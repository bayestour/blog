---
layout: page-sidenav
group: "SDE Theory"
title: "2. Random Variables"
mathjax: true
---

- 확률변수, 확률분포 개념과 연결관계를 이해한다


## 2.1 Introduction

- 통계학은 데이터를 다루는 학문이다. 앞에서 소개한 표본공간(Sample space) 내의 사건(Events)들과 데이터는 어떻게 연결시킬 수 있을까? 


- **확률변수(Random variable)** 는 표본공간 \\( \Omega \\) 의 각 원소 \\(\omega \\) 를 실수공간 \\( \mathbb{R} \\) 내의 값 \\( X(\omega) \\) 로 연결하는 사상(mapping)이다

$$
X : \Omega \longrightarrow \mathbb{R}
$$

- 확률변수의 예 :
	- 동전을 연속해서 10번 던졌을 때(\\(\omega)\\) 앞(\\(H\\))이 나온 횟수를 \\( X(\omega) \\) 로 정의하자. 예를 들어 \\(\omega = HHTHHTHHTT\\) 인 경우 \\(X(\omega)=6\\) 이 된다.
	- 표본공간을 2차원 좌표평면 상의 단위원(unit circle)이라고 하자 \\(\Omega = \\{(x,y):x^{2}+y^{2} \leq 1\\}\\). 이 때 \\(\omega = (x,y)\\) 가 된다. 이 경우 다음과 같은 확률변수들을 생각할 수 있다

$$
X(\omega) = x,\quad Y(\omega)=y, \quad Z(\omega)=x+y,\quad W(\omega)=\sqrt{x^{2}+y^{2}}
$$

![figure2.1]({{ site.baseurl }}/images/aos_Figure2.1.jpeg){:class="center-block" height="200px"}

- 확률변수 \\( X \\) 의 \\( A \subset \mathbb{R} \\) 에 대한 [역상(inverse image)](https://sungbinlim.github.io/sl/docs/mpt/1)을 \\( X^{-1}(A) = \\{\omega\in A : X(\omega)\in A \\} \\) 로 정의한다. \\( X^{-1}(A) \\) 는 \\( \Omega \\) 의 부분집합이므로 확률을 부여할 수 있다:

$$
\mathbb{P}(X \in A)= \mathbb{P}(X^{-1}(A))= \mathbb{P}(\{\omega\in\Omega:X(\omega)\in A\})
$$

$$
\mathbb{P}(X =x)= \mathbb{P}(X^{-1}(\{x\}))= \mathbb{P}(\{\omega\in\Omega:X(\omega)\in\{x\}\})
$$

- 위 기호를 \\( \mathbb{P} (X \in \cdot) = \mathbb{P}_{X} (\cdot) \\) 로도 표기한다. 이는 확률변수 \\( X \\) 에 대응되는 \\( \mathbb{R} \\) 상의 확률측도로써, 앞서 소개한 콜모고로프의 공리를 만족하기 때문이다.

- 앞으로 우리는 \\( \mathbb{P}_{X}(\cdot) \\) 를 \\( X \\) 의 **확률분포(Probability distribution)** 라 부른다.


- **예제** : 다시 동전 던지기를 예로 들어보자. 동전을 두번 던졌을 때 앞이 나온 횟수를 \\( X \\) 로 정의하자. 이 경우 \\( X \\) 의 가능한 역상들은 다음과 같이 세 가지로 나뉜다:

$$
\{X=0\}=\{TT\},\quad \{X = 1\}=\{HT, TH\},\quad \{X=2\}=\{HH\}
$$

- 위 예제에서 각 동전의 outcome 에 대해 \\(\mathbb{P}(\\{HH\\}\)=\mathbb{P}(\\{TH\\}\)=\mathbb{P}(\\{HT\\}\)=\mathbb{P}(\\{TT\\}\)=\frac{1}{4}\\) 로 정의되는 경우 확률분포는 아래와 같이 결정된다:

$$
\mathbb{P}(X=0)=\mathbb{P}(\{ TT\})=\frac{1}{4},\quad \mathbb{P}(X=2)=\mathbb{P}(\{HH\})=\frac{1}{4}
$$

$$
\mathbb{P}(X=1)=\mathbb{P}(\{HT,TH\})=\mathbb{P}(\{HT\})+\mathbb{P}(\{TH\})=\frac{1}{2}
$$

- 앞으로 우리는 확률공간 \\( (\Omega,\mathbb{P}) \\) 을 생략하고 바로 확률변수 \\( X \\) 와 확률분포 \\( \mathbb{P}_{X}(\cdot) \\) 를 언급할 것이다. 그러나 어떤 확률변수와 확률분포든 콜모고로프 공리에 의해 [확률공간을 항상 전제하고 있다](https://sungbinlim.github.io/sl/docs/mpt/2) 는 사실을 유념해야 한다. 


## 2.2 Distribution Functions and Probability Functions

- 이 장에선 확률변수 \\( X \\) 와 확률분포 \\( \mathbb{P}_{X}(\cdot) \\) 가 주어져있다고 가정한다
- **누적분포함수(Cumulative Distribution Function, CDF)** 는 실수공간 \\(\mathbb{R}\\) 에 정의된 함수로 \\( F_{X} \\) 로 표기하고 다음과 같이 정의한다

$$
F_{X}(x) = \mathbb{P}( X\leq x)
$$

- 2.1 에서 소개한 예제로 돌아와보자. \\( \mathbb{P}(X=0) = \mathbb{P}(X=2) =  1/4 \\) 이고 \\( \mathbb{P}(X=1)=1/2 \\) 이므로 \\( F_{X} \\) 는 아래와 같이 유도된다

$$
F_{X}(x) = \begin{cases} 0 & : x < 0 \\ 1/4 & : 0 \leq x < 1 \\ 3/4 & : 1 \leq x < 2 \\ 1 & : 2 \leq x\end{cases}
$$

![figure2.2]({{ site.baseurl }}/images/aos_Figure2.2.png){:class="center-block" height="200px"}

- 우리는 아래 정리를  통해 두 확률변수의 확률분포가 동일한지 판단하려면 누적분포함수만 비교하면 충분하다는 사실을 알 수 있다. (증명은 [Carathéodory extension theorem](https://en.wikipedia.org/wiki/Carath%C3%A9odory%27s_extension_theorem) 을 필요로 하는데, 궁금한 사람은 [R. Durrett](https://www.amazon.com/Probability-Cambridge-Statistical-Probabilistic-Mathematics/dp/0521765390) 책의 Theorem 1.1.2 를 참고하라)

---

**`Theorem 1.`** 확률변수 \\( X \\) 와 \\( Y \\) 의 CDF 를 각각 \\( F_{X}, F_{Y}\\) 라고 하자. 만약 모든 \\( x \in \mathbb{R} \\) 에 대해 \\( F_{X}(x) = F_{Y}(x) \\) 라면 임의의 사건 \\( A \\) 에 대해 \\( \mathbb{P}(X \in A) = \mathbb{P}(Y \in A) \\) 이다


---

- Theorem 1 을 해석할 때 주의할 점은 확률분포가 같다고 해서 확률변수가 같다는 걸 의미하지 않는다는 점이다. 즉 \\( F_{X} = F_{Y} \Rightarrow X = Y \\) 는 성립하지 않는다!

	- 예를 들어 \\( X \\) 가 표준정규분포를 따른다고 하자. \\( Y = -X \\) 라 한다면 \\( Y \\) 도 표준정규분포를 따르므로 \\( F_{X} = F_{Y} \\) 이다. 그러나 \\( \mathbb{P}(X=Y)=\mathbb{P}(X=0)=0 \\), 즉 두 확률변수가 서로 같을 확률은 0 이다. 
	- 확률분포를 안다는 것은 추후 다시 언급하겠지만  **통계량(statistic)** 을 산출할 수 있다는 의미이다. 확률분포를 정확히 안다고 해서 예측을 정확히 하는 것은 불가능하다. 동전 던지기의 분포를 안다고 해서 다음 동전의 결과를 100% 알 수는 없는 것이다.

- Theorem 1 을 통해 누적분포함수를 안다면 확률분포를 특정할 수 있다는 걸 알 수 있다. 그렇다면 어떤 함수가 누적분포함수가 되기 위한 필요충분조건은 무엇일까? 

---

**`Theorem 2.`** 함수 \\( F : \mathbb{R}\to [0,1] \\) 가 누적분포함수가 되기 위한 필요충분건은 아래와 같다 
1. \\( F \\) 는 non-decreasing 이다: \\( x_{1}\leq x_{2} \ \Rightarrow \  F(x_{1}) \leq F(x_{2}) \\) 
2. \\( \lim_{x\to -\infty}F(x)=0\\) 이고 \\( \lim_{x\to \infty} F(x) = 1\\) 이다 
3. \\( F \\) 는 right-continuous 이다: \\( F(x) = \lim_{y \downarrow x}F(y) \\)

---

- Theorem 2 를 해석할 때 주의할 점은, \\( F \\) 가 어떤 확률변수의 누적분포함수가 되는지는 알려주지 않는다. Theorem 1 에서 이미 언급했듯이 누적분포함수는 확률분포를 특정할 뿐 확률변수를 특정하는게 아니기 때문이다

- 누적분포함수와 함께 확률분포를 특정하는 또 다른 함수는 확률질량함수와 확률밀도함수가 있다

- 확률변수가 가질 수 있는 값이 [가산집합(countable set)](https://en.wikipedia.org/wiki/Countable_set) \\( \\{x_{1},x_{2},\ldots \\} \\) 이면 **이산확률변수(discrete random variable)** 라 부른다. 이 때 각 \\( x\in\mathbb{R} \\) 에 대해 \\(f_{X}(x) := \mathbb{P}(X=x) \\) 를 정의하면 이 함수를 **확률질량함수(Probability Mass Function, PMF)** 라 부른다

- 이산확률변수의 CDF 는 다음과 같이 계산된다

$$
F_{X}(x) = \sum_{x_{i}\leq x} f_{X}(x_{i})
$$

- 확률변수 \\( X \\) 가 다음을 만족하는 함수 \\( f_{X} \geq 0\\) 를 가지면 **연속확률변수(continuous random variable)** 라 부른다. 이 때 \\( f_{X} \\) 를 **확률밀도함수(Probability Density Function, PDF)** 라 부른다

$$
\mathbb{P}(a\leq X\leq b) = \int_{a}^{b}f_{X}(t)dt
$$

- 연속확률변수의 CDF 는 다음과 같이 계산된다 

$$
F_{X}(x)=\int_{-\infty}^{x}f_{X}(t)dt
$$

- 연속확률변수의 CDF 를 미분하면 PDF 가 된다

- 이산확률변수나 연속확률변수가 아닌 확률변수도 있다. 