---
layout: post-sidenav
title: "Nonparametric Bayesian 이란?"
group: "Bayesian Statistics"
author: 임성빈
---

이번 포스트에서는 Nonparametric Bayesian 이 무엇인지 원리적인 부분에 대해 소개하고자 합니다.

**Nonparametric Bayesian** 은 이름에서 볼 수 있듯이 두 통계학 용어를 섞어 놓은 분야입니다. 요약하면 Bayesian 방식으로 nonparametric model 을 다루는 방법론입니다. 이 말을 자세히 이해하기 위해 먼저 이 블로그에서 다룰 **모델(model)** 의 정의가 무엇인지 자세히 이해해보도록 하겠습니다.

정량적인(quantitative) 분석이 요구되는 분야를 공부하다 보면 모델링이 무엇인지에 대해 한번쯤 고민하게 됩니다. 물리적 법칙 또는 governing dynamics 를 반영하여 모델을 deterministic 형태로 기술할 수도 있지만 이는 굉장히 제한된(혹은 통제된) 환경에서 사용 가능한 것입니다. 반면 데이터를 기반으로 적절한 가정 하에 **[통계적 모형(statistical model)](https://en.wikipedia.org/wiki/Statistical_model)** 을 구축해서 적용할 수 있습니다.

### 통계적 모델(statistical model)이란?

통계적 모델이 무엇인지 이해하기 위해 예제를 하나 들어보겠습니다 (참조출연: [오하이오의 낚시꾼](https://www.facebook.com/fisherinohio/)).

> Q: 오하이오 식당을 운영하는 낚시꾼은 서빙을 담당할 직원을 뽑으려고 한다. 한 직원이 시간대별로 응대할 수 있는 테이블의 숫자는 1개이고, 전체 테이블의 개수가 10개라고 하자. 직원을 몇 명을 뽑아야 할까?

위 문제를 언뜻 보면 전체 테이블 숫자와 같은 10명을 뽑아야 할듯 합니다. 그러나 실제 문제는 이렇게 간단하지 않습니다. 왜냐하면 현실에선 낚시꾼은 다음과 같은 변수들을 같이 고려해야 하기 때문입니다.

1. 직원에게 지불해야 하는 시급: \\( P \\)
2. 시간대 \\( t \\) 테이블 \\( i \\) 에서 발생하는 수입: \\( M(i,t) \\)
3. 시간대 \\( t \\) 별 식당을 방문하는 손님 그룹의 수: \\( N(t) \\)

여기서 \\( P \\) 는 고정된 비용이므로 결정적(deterministic) 변수 입니다 (낚시꾼은 마음이 착해서 최저임금보다 높게 준다고 가정합시다). 그러나 2, 3번의 \\( M(i,t), N(t)\\) 는 **확률적인(stochastic)** 변수로 매시간마다 바뀌게 됩니다. 만약 직원을 테이블 숫자만큼 채용하게 되면 테이블이 모두 꽉차는 피크 시간대에는 괜찮을지 몰라도 그렇지 않은 시간대는 손해를 보게 됩니다.

낚시꾼이 하루에 \\( T \\) 시간동안 이 식당을 운영한다고 했을 때, \\( X \\) 명을 뽑는 경우 발생하는 수입 \\( I \\) 과 지출 \\( C \\) 은 아래와 같습니다 (여기서 기호 \\( x \wedge y \\) 는 \\( \min\\{ x , y \\} \\) 를 말합니다).

$$
I = \sum_{t=1}^{T}\sum_{i=1}^{X \wedge N(t)} M(i,t), \quad C = PTX
$$

낚시꾼이 이 식당을 폐업 없이 운영하려면 \\( I > C \\) 상태를 유지해야 합니다. 그러기 위해선 \\( N(t) \\) 와 \\( M(i,t) \\) 정보를 알아야 합니다. 이 두 가지 정보는 데이터를 통해서 알아낼 수 있습니다.

### 통계적 모델의 종류: parametric vs nonparametric

데이터가 관찰 또는 수집되는 공간을 \\( \mathcal{X} \\) 라고 표기하겠습니다. 이 공간을 우리는 데이터 공간(data space) 또는 표본 공간(sample space)이라고 부릅니다. 수학 시간 때 배워온 자연수(\\( \mathbb{N} \\)), 정수(\\( \mathbb{Z} \\)), 실수(\\( \mathbb{R},\mathbb{R}^{d} \\)), 복소수(\\( \mathbb{C} \\)) 집합 등 우리가 데이터 분석에서 흔히 사용하는 공간들이 \\( \mathcal{X} \\) 의 예 입니다 [2].

그리고 이 공간 위에서 여러 확률분포(probability distribution)들을 정의할 수 있습니다. 가령 실수(\\( \mathbb{R} \\)) 공간이라면 정규분포(normal distribution) \\( \mathcal{N}(\mu,\sigma^{2}) \\) 나 지수분포(exponential distribution) \\( \text{Exp}(\lambda) \\) 등을 정의할 수 있겠지요. 이 확률분포들을 모두 모아놓은 집합을 우리는 \\( \mathbf{PM}(\mathcal{X}) \\) 라고 표기하겠습니다. 당연하지만 이런 확률분포들은 **셀 수 없을 정도로 무한히** 많습니다 [2]. 어떤 확률분포를 사용해서 공간 \\( \mathcal{X} \\) 를 모델링(modeling)할지는 데이터를 통해 연구자가 (혹은 컴퓨터가) 판단을 내려야 합니다.

![figure]({{ site.baseurl }}/images/posts/models-npb.png){:class="center-block" height="500px"}
**여러 종류의 확률분포, 출처: [https://priorprobability.com](https://priorprobability.com/2016/09/18/taxonomy-of-univariate-distributions/)**

어떤 분포가 주어진 데이터를 모델링하기 적절한지 비교 분석을 하려면 모수 공간(parameter space)을 상정해야 합니다.

![figure]({{ site.baseurl }}/images/posts/density-npb.png){:class="center-block" height="150px"}
**모수적(parametric) 방법 vs 비모수적(nonparametric) 방법, 출처: P. Orbanz, 2014**

$$
M(\Theta):=\{P_{\theta}:\theta \in \Theta \} \subset \mathbf{PM}(\mathcal{X})
$$

결정짓는 건 모수(parameter)인 평균 \\( \mu \\) 와 표준편차 \\( \sigma \\) 입니다.

### Probability: a measure of uncertainty

통계학이나 머신러닝 이론을 다루는 어떤 교과서든 첫 장부터 대게 확률론(probability theory)을 먼저 배우게 됩니다. 확률은 불확실한 문제 상황에서 실현 가능한 경우의 수 들을 고려해 전체 상황 중 어떤 사건이 발생할 가능성이 얼마나 되는지 척도(yardstick)로 삼을 때 유용합니다. 간단한 예로는 주사위 2개를 던졌을 때 합이 7 이 나올 확률은 얼마인지, 동전을 5번 던졌을 때 앞면이 연속해서 3번 나올 확률은 얼마인지 등의 문제를 풀 때, 우리는 가능한 경우들을 모두 생각해보고, 그 중 관심을 가지는 사건이 일어날 경우의 수를 세어봅니다.

![figure]({{ site.baseurl }}/images/posts/dice-npb.png){:class="center-block" height="200px"}
**주사위 2개를 던졌을 때 가능한 합의 경우의 수와 확률분포, 출처: [Math Stack Exchange](https://math.stackexchange.com/questions/1204396/why-is-the-sum-of-the-rolls-of-two-dices-a-binomial-distribution-what-is-define)**

현실 문제에서는 임상 실험이나 주식 투자, 기업 의사결정 같은 문제에서 가변적이고 다루기 까다로운 조건들을 변수로 고려해야 할 때 확률을 사용할 수 있습니다. 물론 이런 접근이 100% 맞는 것은 절대 아닙니다. 그러나 **불확실성의 측도(measure of uncertainty)** 라는 관점에서 확률은 현재까지는 제일 유용한 수학적 도구입니다 [1].

### 확률분포의 확률분포?

Bayesian Inference 는 흔히들 [Bayes 정리 (Bayes' theorem)](https://en.wikipedia.org/wiki/Bayes%27_theorem) 에 근간을 둔다고 합니다. 틀린 말은 아닙니다만, Bayes 정리를 사용한다고 모델이 무조건 Bayesian 이 된다는 뜻이 아닙니다.

![figure]({{ site.baseurl }}/images/posts/bayes-npb.png){:class="center-block" height="300px"}
**A Flow of Bayesian Inference, 출처: [J. C. Doll & S. J. Jacquemin, 2018](https://afspubs.onlinelibrary.wiley.com/doi/full/10.1002/fsh.10038)**

Bayesian Statistics 의 기본적 전제는 모수(parameter)를 확률변수로 다루는 겁니다. 이 모수의 확률분포를 **사전분포(prior distribution)** 라 합니다.


### Comment

[1] 이런 해석에 대해 좀 더 궁금하신 분은 Bernardo 와 Smith 의 참고문헌(2000) 참조.

[2] 이론적으로는 [Borel measure](https://en.wikipedia.org/wiki/Borel_measure) 를 정의할 수 있는 [거리공간(metric space)](https://en.wikipedia.org/wiki/Metric_space)이면 우리가 기본적으로 다룰 수 있는 공간입니다.

[3] 여기서 [셀 수 없다(uncountable)](https://en.wikipedia.org/wiki/Uncountable_set) 라는 의미는 수사적인 표현이 아니라 수학적인 용어입니다. 어떤 뜻인지 궁금하시다면 집합론(set theory) 교과서를 한 번 읽어보시길 추천합니다.



### 참고문헌

- *Bayesian Theory*, J.M. Bernardo, A.F.M. Smith, 2000
- *Lecture Notes on Bayesian Nonparametrics*, P. Orbanz, 2014
- *Bayesian Nonparametrics*, J.K. Ghosh, R.V. Ramamoorthi, 2003
- *Bayesian Data Analysis*, A. Gelman, J.B. Carlin, H.S. Stern, D.B. Dunson, A. Vehtari, D.B. Rubin, 2013
- *Introduction to Bayesian Modeling and Inference for Fisheries Scientists*, J. C. Doll, S. J. Jacquemin, 2018
