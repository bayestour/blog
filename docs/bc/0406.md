---
layout: page-sidenav
group: "Regularization"
title: "6. Regularization and RKHS"
---

- Regularization 항이 도입된 알고리듬들은 아래와 같이 일반적으로 표현할 수 있다. \\( L \\) 은 loss 함수이고 \\( J \\) 는 penalty 연산자인데, \\( f\in\mathcal{H} \\) 위에 적용된다. 이 함수공간 \\( \mathcal{H} \\) 는 solution space 에 해당한다

$$
\min_{f\in\mathcal{H}}\left[ \sum_{i=1}^{N}L(y_{i}, f(x_{i}))+\lambda J(f) \right]\quad\cdots\quad (1)
$$

- Girosi 는 일찍이 아래와 같은 형태의 penalty 연산자를 도입한 적이 있다. \\( \mathcal{F}[\cdot] \\) 는 Fourier transform 을 의미한다

$$
J(f) = \int_{\mathbb{R}^{d}} |\mathcal{F}[f](\xi)|^{2} \frac{d\xi}{\mathcal{F}[\psi](\xi)} 
$$

- 위 식에서 \\( \mathcal{F}[\psi] (\xi) \\) 는 \\( \vert \xi \vert \to \infty \\) 일 때 0 으로 decay 하는 함수이다. \\( \mathcal{F}[\psi] \\) 의 역할은 \\( \mathcal{F}[f] \\) 의 high frequency 영역에 강한 penalty 를 부여한다

- 몇 가지 추가적인 가정이 있으면, 위 학습문제의 해는 아래와 같은 형태임을 증명할 수 있다. \\( \{ \phi_{k} \} \\) 는 \\( J \\) 의 null space 의 basis 들이다.

$$
f(X) = \sum_{k=1}^{K}\alpha_{k}\phi_{k}(X) + \sum_{i=1}^{N} \theta_{i}\psi(X - x_{i})
$$

- 식 (1) 에서 분명 \\( \mathcal{H} \\) 는 무한차원을 가진 공간도 허용하지만, 위에서 유도된 해는 유한개의 기저로 표현되는 것이 특징이다. 앞에서 소개한 spline 방법들은 여기에 속하게 된다

---




<img src="{{ site.baseurl }}/images/mpsl_Figure030101.png" width="3%" height="3%" /> 

![figure1.1]({{ site.baseurl }}/images/mpsl_Figure010101.png){:class="center-block" height="200px"}

---

`Definition 1`. 임의의 $$ x,y,z \in \mathcal{X} $$ 에 대해 다음 네 조건을 만족하는 함수 $$ d:\mathcal{X}\times\mathcal{X}\to\mathbb{R} $$ 를 **거리함수(distance function)** 라 부른다

1. 항상 양수이다 : \\( d(x,y)\geq 0 \\)
2. 거리가 0 이면 같은 원소다 : \\( d(x,y)=0 \\) 이기 위한 필요충분조건은 \\( x=y \\) 이다
3. 대칭성을 가진다 : \\( d(x,y) = d(y,x) \\)
4. 삼각부등식을 만족한다 : \\( d(x,y) \leq d(x,z) + d(z,y) \\)

---




