---
layout: page-sidenav
group: "Chapter. 4"
title: "5. Bayesian Logistic Regression"
---

- 이제 로지스틱 회귀 문제에 베이지안 추론을 도입할 차례이다. (알다시피 Bishop 은 베이지안 덕후)
- 사실 로지스틱 회귀에 베이지언 추론을 적용하기는 쉽지 않다. (원래 intractable 속성이다.)
    - 따라서 사전 확률 분포와  *likelihood* 함수의 곱을 정규화 하는 과정이 필요하다.
- 또한 베이지안 추론에서 빠질 수 없는 예측 분포(predictive distribution)도 도출해 보도록 하자.

## 4.5.1 라플라스 근사 (Laplace approximation)

- 4.4 절에서 소개한 라플라스 근사법을 파라미터 \\( {\bf w} \\) 의 사후 분포를 근사하는데 사용할 것이다.
    - 사후 분포를 가우시안의 중앙에 맞추는 작업을 진행하게 된다.
    - 이러한 작업에는 로그 사후 분포를 두번 미분해야 하는 작업이 필요하다. (헤시안 행렬을 구하기 위해)
- 일단 \\( {\bf w} \\) 의 사전 분포로 가우시안 분포를 고려한다.

$$p({\bf w}) = N({\bf w}|{\bf m}_0, {\bf S}_0) \qquad{(4.140)}$$

- 여기서 \\( {\bf m}\_0 \\) 와 \\({\bf S}\_0 \\) 는 고정된 초모수(hyper-parameter)이다.
- 이제 \\( {\bf w} \\) 의 사후 분포를 생각해보자.

$$p({\bf w}|{\bf t}) \propto p({\bf w})p({\bf t}|{\bf w}) \qquad{(4.141)}$$

- 여기서 \\( {\bf t} \\) 는 \\( {\bf t} = (t\_1,...,t\_N)^T \\) 이다.
- 사후 분포에 로그를 취해 식을 전개해 보도록 하자.

$$\ln({\bf w}|{\bf t}) = - \frac{1}{2}({\bf w}-{\bf m}_0)^T{\bf S}_0^{-1}({\bf w}-{\bf m}_0) + \sum_{n=1 }^{N} \{t_n \ln y_n + (1-t_n)\ln(1-y_n) \} + const \qquad{(4.142)}$$

- 이 때 \\( y\_n = \sigma({\bf w}^T \phi_n) \\) 이다.
- 가우시안 근사 사후 분포를 얻기 위해서 가장 먼저 사부 분포의 값을 최대화 하는(MAP : maximum a posterior) 지점을 찾아야 한다.
    - 이 위치를 \\( {\bf w}\_{MAP} \\) 이라고 하자. 이는 근사할 가우시안 함수의 중앙 위치가 된다. (기대값으로 사용된다.)
- 가우시안 근사 분포의 분산 값을 고려해보자.
    - 여기서는 계산의 편리성을 위해 정확도(precision) 단위로 식을 전개하도록 하자.

$$S_N^{-1} = -\nabla\nabla \ln p({\bf w}|{\bf t}) = {\bf S}_0^{-1} + \sum_{n=1}^{N} y_n(1-y_n)\phi_n\phi_n^T \qquad{(4.143)}$$

- 이제 최종적으로 가우시안 근사 분포를 다음과 같이 정의하면 된다.

$$q({\bf w}) = N({\bf w}|{\bf w}_{MAP}, {\bf S}_N) \qquad{(4.144)}$$

- 이 값을 활용하여 예측 분포를 작성하면 된다.

## 4.5.2 예측 분포 (Predictive distribution)

- 새로운 데이터 \\( {\bf x} \\) 가 주어졌을 때 클래스 \\( C\_1 \\) 에 속하는 확률을 알아보기 위한 예측 분포를 작성하는 식을 만들어보자.
    - 문제를 단순하게 하기 위해서 2-class 문제를 다루어보도록 하자.
- 앞서 사후 분포 \\( p( {\bf w} \| {\bf t}) \\) 를 가우시안 근사 함수로 처리하면 된다고 이야기했었다.
    - 참고로 입력 속성(feature)은 \\( \phi({\bf x}) \\) 로 입력되게 된다.

$$p(C_1|\phi, {\bf t}) = \int p(C_1|\phi, {\bf w})p({\bf w}|{\bf t})d{\bf w} \simeq \int \sigma({\bf w}^T \phi)q({\bf w})d{\bf w} \qquad{(4.145)}$$

- 식을 잘 보면 사후 분포가 근사 분포인 \\( q \\) 로 대치되었다는 것을 알 수 있다.
- 마찬가지로 \\( C\_2 \\) 에 대응되는 사후 확률은 \\( p(C\_2\|\phi, {\bf t}) = 1 - p(C\_1\|\phi, {\bf t}) \\) 로 생각할 수 있다.

- 예측 확률 분포를 작성하기 위해서 먼저 \\( {\bf w} \\) 에 대한 함수 \\( \sigma({\bf w}^T\phi) \\) 를 \\( \phi \\) 로 투영(projection)해야 한다.
    - 입력 벡터 \\( {\bf x} \\) 가 기저 함수인 \\( \phi \\) 로 변환되므로 일단 이 단위로 데이터를 변환시킨다.
    
$$\sigma({\bf w}^T\phi) = \int \delta(a-{\bf w}^T\phi)\sigma(a)da \qquad{(4.146)}$$

- 뜬금없이 이러한 변형식이 나왔는데 교재에는 자세한 설명이 없다.
    - 이와 관련된 내용은 조금 뒤에 하기로 하고 우선은 이런 식으로 변환이 가능하다고 생각하고 전개를 해보도록 하자.
    - 여기서 \\( \delta(\cdot) \\) 는 `Dirac delta` 라고 불리우는 함수이다.
    - 어쨌거나 이 식을 다시 식 (4.145) 에 대입하면 다음 식을 얻게 된다.
    
$$\int \sigma({\bf w}^T\phi)q({\bf w})d{\bf w} = \int \sigma(a)p(a)da \qquad{(4.147)}$$

$$p(a) = \int \delta(a-{\bf w}^T\phi)q({\bf w})d{\bf w} \qquad{(4.148)}$$

- 위와 같은 식을 얻는다.
- 이 식에서 \\( p(a) \\) 는 결국 가우시안 분포가 된다.
    - 일단 \\( q({\bf w}) \\) 는 정의에 의해 가우시안 분포.
    - \\( \delta(a - {\bf w}^T\phi) \\) 는 \\( {\bf w} \\) 에 대한 선형 제약식(linear constraint)으로 생각할 수 있다.
    - \\( p(a) \\) 는 결국 \\( \phi \\) 의 방향과 수직(orthogonal)인 모든 방향에 대해 결합 분포 \\( q({\bf w}) \\) 를 주변화(marginal) 하는 식이 된다.
    - 이 분포는 결국 가우시안 분포가 되는데 이는 이미 2.3.2 절에서 다룬 내용이다.
- 이 가우시안 분포의 평균과 분산은 다음과 같다.
    
$$\mu_a = E[a] = \int p(a)a da = \int q({\bf w}){\bf w}^T \phi d{\bf w} = {\bf w}_{MAP}^T\phi \qquad{(4.149)}$$

$$\sigma_a^2 = var[a] = \int p(a)\{ a^2 - E[a]^2 \}da = \int q({\bf w}) \{({\bf w}^T\phi)^2 - ({\bf m}_N^T\phi)^2 \}d{\bf w} = \phi^T{\bf S}_N\phi \qquad{(4.150)}$$

- 이 식이 (식 3.58) 과 동일함을 확인하도록 하자.
    - 물론 현재는 분류 문제를 다루고 있기 때문에 노이즈의 분산 \\( \beta \\) 는 \\( 0 \\) 인 경우와 같다.

- 이제 예측 분포의 변분 근사(variational approximation)는 다음과 같이 생각할 수 있다.

$$p(C_1|{\bf t}) = \int \sigma(a)p(a)da = \int \sigma(a)N(a|\mu_a, \sigma_a^2)da \qquad{(4.151)}$$

- 이 식도 마챁가지로 2.3.2 절에서 다룬 식을 통해 직접 유도가 가능하다.

#### Inverse probit function 을 사용한 근사법

- (식 4.151)은 사실 logistic sigmoid 와 가우시안의 콘볼루션(convoltion) 식인데 이 식은 (식 4.114)에 정의된 Invert Probit 함수로 근사 가능하다.
    - 즉, \\( \sigma(a) \simeq \Phi(\lambda a) \\) 로 근사하게 된다.
    - 로지스틱 시그모이드와 probit 함수의 유사성은 이미 (그림 4.9)로 살펴보았다.
    - 참고로 \\( \lambda = \pi / 8 \\) 인 경우 (그림 4.9) 에서처럼 함수의 결과가 유사해진다.

- 근사 식으로 전개하여보자.
    
$$\int \Phi(\lambda a)N(a|\mu, \sigma^2)da = \Phi \left(\frac{\mu}{(\lambda^{-2}+\sigma^2)^{1/2}}\right) \qquad{(4.152)}$$

$$\int \sigma(a)N(a|\mu, \sigma^2)da \simeq \sigma(k(\sigma^2)\mu) \qquad{(4.153)}$$

$$k(\sigma^2) = (1+\pi \sigma^2 / 8)^{-1/2} \qquad{(4.154)}$$

- 여기서 (식 4.151) 에 적용하면 다음의 식을 얻을 수 있다.

$$p(C_1|\phi, {\bf t}) = \sigma(k(\sigma_a^{2})\mu_a) \qquad{(4.155)}$$


- 참고로 결정 경게는 \\( p(C\_1 \| \phi, {\bf t}) = 0.5 \\) 인 지점으로 찾을 수 있다. ( \\( \mu\_a = 0 \\) )
- 이 경우 \\( {\bf w} \\) 의 MAP 값을 사용하여 얻은 결정 경계와 동일한 결과를 얻게 된다.
