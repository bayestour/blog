---
layout: page-sidenav
group: "Understanding Machine Learning"
title: "Part 1. Foundations"
---

- 1장에서는 기초 확률 이론을 이용하여 패턴 인식의 여러 문제들을 간단하게 살펴보았다.
- 이번 장에서는 다양한 확률 분포를 먼저 살펴보는 시간을 가진다.
- 좀 재미 없는 영역이지만 이후에 빈번하게 사용되는 기초 내용이 수록되어 있으니 꼼꼼하게 읽어야 한다.
- 여기서는 랜덤 변수 \\( x \\) 에 대해 확률 함수 \\( p(x) \\) 를 모델링하는 것을 배운다.
- 이것을 밀도 추정(density estimation)이라고 한다.
- 우선 가장 먼저 고려해야 할 것은 모든 샘플 데이터는 독립적으로 생성되었다고 가정하는 것이다.
- 사실 관찰된 데이터로 부터 추측해볼 수 있는 확률 분포는 정말 끝도없이 많을 것이다.
- 물론 어떤 모델을 선택하여야 할 것인가의 문제는 1장의 커브 피팅 문제에서도 살짝 다루긴 했다.
- 우리는 먼저 파라미터를 가지고 있는 분포들(parametric distribution)을 살펴볼 예정이다.
    - 이건 거의 정형화되어 있는 분포들이다.
- 가우시안 분포도 이러한 분포 중 하나이며, 이번 장에서도 자세히 다룰 예정이다.
- 또한 우리는 공액 사전 분포(conjugate prior distribution)라는 것도 잠시 다루어볼 예정이다.
- 이 분포는 사후 분포(posterior distibution)를 수학적으로 계산하기 쉽도록 도움을 준다.
    - 예를 들어 베타(Beta) 분포나 디리슈레(Dirichlet) 분포 등이 있다.
- 이런 분포들을 살펴보면서 지수 분포족(exponetial family of distrivution)도 살펴볼 것이다.
- 파라미터를 가지는 분포의 한계점은 함수 자체가 이미 특별한 형태의 구조를 포함하고 있다는 것이다
    - 따라서 실제 샘플과 다른 양상의 분포를 선택하게 되는 경우 원하는 결과를 얻지 못할 때가 많다.
    - 마지막에는 파라미터를 사용하지 않는 분포에 대한 모델링도 살펴볼 것이다.
