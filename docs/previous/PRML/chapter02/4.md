---
layout: page-sidenav
group: "Understanding Machine Learning"
title: "7. Nonuniform Learnability"
---

- 지금까지 확률 분포가 무엇인지 줄기차게 배웠다.
- 사실 지금까지 다루었던 확률 분포들 중에 일부는 지수 분포족(exponential family)이라 불리우는 집합군에 속한다.
- 지수 분포족에 속하는 분포들은 공통된 특징을 내포하고 있는데 이번 절에서 이를 일반화하여 설명하고자 한다.
- 지수분포족에 속하는 분포는 다음과 같은 형태의 일반화된 분포 식으로 표현할 수 있다.

$$p({\bf x}|{\bf \eta})=h({\bf x})g({\bf \eta})\exp\{ {\bf \eta}^T{\bf u}({\bf x})\} \qquad{(2.194)}$$

- 여기서 입력 데이터 \\( {\bf x} \\) 는 벡터일수도 있고 스칼라 값일수도 있다. (물론 연속/불연속 여부도 상관 없다.)
- \\( {\bf \eta} \\) 는 자연 모수 (natural parameters)라고 부른다.
- \\( {\bf u}({\bf x}) \\) 는 \\( {\bf x} \\) 에 대한 어떤 함수이다.
- \\( g({\bf \eta}) \\) 는 확률 분포에 대한 정규화 계수로 확률의 전체 합을 1로 맞추는데 사용되는 요소이다.

$$g({\bf \eta})\int h({\bf x})\exp\{ {\bf \eta}^T{\bf u}({\bf x})\}d{\bf x}=1 \qquad{(2.195)}$$

- 위와 같은 형태를 취하는 분포를 지금까지 배운 적이 없다고 생각할 수도 있다.
- 하지만 지금까지 배운 많은 분포들이 위와 같은 일반화 식 형태으로 변경 가능하다.

-----

**베르누이 분포**

- 가장 먼저 베르누이 분포(Bernoulli distribution)가 지수 분포에 속하는지를 확인해보도록 한다.

$$p(x|\mu) = Bern(x|\mu)=\mu^x(1-\mu)^{1-x} \qquad{(2.196)}$$

- 이를 지수분포족의 형태로 변환 가능할까?

$$p(x|\mu) = \exp \{x\ln\mu + (1-x)\ln(1-\mu)\}\\\\=(1-\mu)\exp\left\{\ln\left(\dfrac{\mu}{1-\mu}\right)x\right\} \qquad{(2.197)}$$

- 충분히 가능하다.
- 분포 식에서 \\( \exp(\cdot) \\) 형태를 만들어내기 위해 \\( \exp(\cdot) \\) 과 \\( \ln(\cdot) \\) 을 적절하게 이용하여 변형한다.
    - \\( f(x)=\exp(\ln{f(x)}) \\) 를 활용한다.
- 위의 식에서 \\( \eta \\) 는 다음과 같다.
    
$$\eta = \ln\left(\dfrac{\mu}{1-\mu}\right) \qquad{(2.198)}$$

- \\( \mu=\sigma(\eta) \\) 를 놓고 다른 형태로 식을 만들 수도 있다.

$$\sigma(\eta)=\dfrac{1}{1+\exp(-\eta)} \qquad{(2.199)}$$

- 이거 어디서 많이 보던 식이다.
    - 이를 로지스틱 회귀(logistic regression)라고 부른다.
    - 베르누이를 적절하게 변형하면 로지스틱 회귀 식이 나오는 것을 확인할 수 있다.

$$p(x|\eta)=\sigma(-\eta)\exp(\eta x) \qquad{(2.200)}$$

- \\( 1-\sigma(\eta)=\sigma(-\eta) \\) 를 이용하면 다음과 같이 식을 확인할 수 있다.

$$u(x) = x \qquad{(2.201)}$$

$$h(x) = 1 \qquad{(2.202)}$$

$$g(\eta) = \sigma(-\eta) \qquad{(2.203)}$$

- 따라서 베르부이 분포는 지수 분포족에 속한다.

-----

**다항분포**

- 다음으로 다항분포(multinomial distribution)도 살펴보도록 하자.

$$p({\bf x}|{\bf \mu}) = \prod_{k=1}^{M}\mu_k^{x_k}=\exp\left\{\sum_{k=1}^{M}x_k\ln\mu_k\right\} \qquad{(2.204)}$$

- 여기서 \\( {\bf x}=(x_1,...,x_M)^T \\) 이다.
- 다시한번 표준화된 식으로 변형해보면 다음과 같이 식을 전개할 수 있다.

$$p({\bf x}|{\bf \eta})=\exp({\bf \eta}^T{\bf x}) \qquad{(2.205)}$$

- 여기서 \\( \eta\_k=\ln\mu\_k \\) 이다. 단, \\( {\bf \eta}=(\eta\_1,...,\eta\_M)^T \\) 이다.
- 최종으로 얻어지는 식은 다음과 같다.

$$u(x) = {\bf x} \qquad{(2.206)}$$

$$h(x) = 1 \qquad{(2.207)}$$

$$g(\eta) = 1 \qquad{(2.208)}$$

- 다항분포의 조건에 따라 다음이 성립한다. (제약 사항임)

$$\sum_{k=1}^{M}\mu_k=1 \qquad{(2.209)}$$

- 이 식은 다음과 같이 생각할 수도 있음.

$$0\le\mu_k\le 1 \qquad{(2.210)}$$

$$\sum_{k=1}^{M-1}\mu_k \le 1 \qquad{(2.210)}$$

- 위와 같은 제약을 염두에 두고 다시 표준화된 식으로 전개하면 다음과 같다.

$$\exp\left\{\sum_{k=1}^{M}x_k\ln\mu_k\right\} = \exp\left\{\sum_{k=1}^{M-1}x_k\ln\mu_k + \left(1-\sum_{k=1}^{M-1}x_k\right)\ln\left(1-\sum_{k=1}^{M-1}\mu_k\right) \right\}\\
= \exp\left\{\sum_{k=1}^{M-1}x_k\ln\left(\frac{\mu_k}{1-\sum_{j=1}^{M-1}\mu_j}\right)+\ln\left(1-\sum_{k=1}^{M-1}\mu_k\right)\right\} \qquad{(2.211)}$$

- 상수 부분은 밖으로 빼내고 식을 살펴보면 다음을 알 수 있다.

$$\ln\left(\frac{\mu}{1-\sum_{j}\mu_j}\right)=\eta_k \qquad{(2.212)}$$

- 이를 \\( u_k \\) 에 대해 전개하면 다음과 같은 식을 얻는다.

$$\mu_k=\dfrac{\exp(\eta_k)}{1+\sum_j\exp(\eta_j)} \qquad{(2.213)}$$

- 오, 이것도 어디서 많이 보던 식이다.
- 이를 *softmax* 라고 부른다. (혹은 정규지수 : Normalized Exponential 라고 부른다.)
- 어쨌거나 전체 식을 살펴보자.

$$p({\bf x}|{\bf \eta}) = \left(1+\sum_{k=1}^{M-1}\exp(\eta_k)\right)^{-1}\exp({\bf \eta}^T{\bf x}) \qquad{(2.214)}$$

- 이제 최종 식을 기술할 수 있다.

$${\bf u}({\bf x})={\bf x} \qquad{(2.215)}$$

$$h({\bf x})=1 \qquad{(2.216)}$$

$$g({\bf \eta}) = \left(1+\sum_{k=1}^{M-1}\exp(\eta_k)\right)^{-1} \qquad{(2.217)}$$

- 이 때 \\( {\bf \eta} \\) 는 \\( {\bf \eta} = (\eta_1,...,\eta_{M-1},0)^T \\) 가 된다.
- 따라서 다항 분포도 마찬가지로 지수 분포이다.

-----

**정규분포**

- 마지막으로 정규 분포에 대해서도 살펴본다.
- 마찬가지로 정규 분포는 식 자체로 지수 분포족임을 알 수 있다.
- 여기서는 최대한 간단히 정리만 한다.

$$p(x|\mu,\sigma^2)=\dfrac{1}{(2\pi\sigma^2)^{1/2}}\exp\left\{-\frac{1}{2\sigma^2}(x-\mu)^2\right\} \qquad{(2.218)}\\
= \dfrac{1}{(2\pi\sigma^2)^{1/2}}\exp\left\{-\frac{1}{2\sigma^2}x^2+\frac{\mu}{\sigma^2}x-\frac{1}{2\sigma^2}\mu^2\right\} \qquad{(2.219)}$$

- 최종 식은 다음과 같다.

$${\bf \eta} = \dbinom{\mu/\sigma^2}{-1/2\sigma^2} \qquad{(2.220)}$$

$${\bf u}(x) = \dbinom{x}{x^2} \qquad{(2.221)}$$

$$h(x)=(2\pi)^{-1/2} \qquad{(2.222)}$$

$$g({\bf \eta})=(-2\eta_2)^{1/2}\exp\left(\frac{\eta_1^2}{4\eta_2}\right) \qquad{(2.223)}$$


## 2.4.1. 가능도 함수와 충분 통계량 (Maximum likelihood and sufficient statistics)

- 이제 지수족 분포에서 파라미터 벡터 \\( {\bf \eta} \\) 를 추정하는 문제를 다루어 볼 것이다.
    - 이 때 *MLE* 를 사용하여 이 값을 추정한다.
    - \\( {\bf \eta} \\) 에 대한 미분값을 살펴보자.

$$\nabla g({\bf \eta})\int h({\bf x})\exp\{ {\bf \eta}^T {\bf u}({\bf x})\}d{\bf x} + g({\bf \eta})\int h({\bf x})\exp\{ {\bf \eta}^T{\bf u}({\bf x})\}{\bf u}({\bf x})d{\bf x} = 0 \qquad{(2.224)}$$

- \\( \int h({\bf x})\exp\{ {\bf \eta}^T{\bf u}({\bf x})\}d{\bf x} = 1/g({\bf \eta}) \\) 이므로 (식, 2.195 에 의해) 위의 식을 다음과 같이 정리할 수 있다.

$$-\frac{1}{g({\bf \eta})} \nabla g({\bf \eta}) = g({\bf \eta})\int h({\bf x})\exp\{ {\bf \eta}^T{\bf u}({\bf x})\}{\bf u}({\bf x})d{\bf x}=E[{\bf u}({\bf x})] \qquad{(2.225)}$$

- 최종적으로 다음과 같은 식을 얻는다. (좌변을 보면 \\( \ln(\cdot) \\)  의 미분값임.)

$$-\nabla \ln g({\bf \eta}) = E[{\bf u}({\bf x})] \qquad{(2.226)}$$

- \\( g({\bf \eta}) \\) 를 두번 미분한 결과는 \\( {\bf u}({\bf x}) \\) 의 공분산 값이 된다.
    - 이 때 이 공분산은 양 정부호 (positive definite)를 만족한다.
    - 따라서 \\( g({\bf \eta}) \\) 함수는 `convex` 조건을 만족한다.
    - 교재에 증명은 생략되어 있다.

- 이제 서로 독립인(i.i.d) 관찰 데이터 \\( {\bf X}=\{ {\bf x\_1}, ..., {\bf x}\_N\} \\) 이 주어졌을 때 가능도 함수를 살펴보자.

$$p({\bf X}|{\bf \eta}) = \left(\prod_{n=1}^{N}h({\bf x}_n)\right) g({\bf \eta})^N \exp\left\{ {\bf \eta}^T\sum_{n=1}^{N}{\bf u}({\bf x}_n)\right\} \qquad{(2.227)}$$

- 로그를 붙인 후 \\( {\bf \eta} \\) 에 대해 미분하여 값을 0이 된다고 해서 전개를 하면 \\( {\bf \eta}_{ML} \\) 값을 얻을 수 있다.

$$-\nabla \ln g({\bf \eta}_{ML}) = \frac{1}{N}\sum_{n=1}^{N}{\bf u}({\bf x}_n) \qquad{(2.228)}$$

- 위의 식을 통해 \\( \sum_n {\bf u}({\bf x}_n) \\) 을 분포에 대한 충분 통계(*sufficient statistic* ) 라고 한다.
    - 충분 통계는 앞서서 몇 번 언급이 되기는 했는데, 모수 값을 완전히 설명할 수 있는 최소한의 함수식이라고 생각하면 된다.
    - 따라서 우리는 모든 데이터를 계산시에 다 저장해서 사용할 필요가 없이 이 식에 나온 결과만을 저장하여 모수 추정에 활용하면 된다.
    - *베르누이*  : 베르누이에서는 \\( {\bf u}(\bf x) \\) 가 \\( {\bf x} \\) 이므로 우리는 단지 입력되는 데이터를 계속 누적하기만 하면 된다.
    - *가우시안* : 가우시안에서는 \\( {\bf u}(\bf x) \\) 가 \\( {\bf u}({\bf x}) = (x, x^2)^T \\) 이므로 \\( x \\) 의 합과 \\( x^2 \\) 의 합만을 유지하면 된다.

- 만약 \\( N\rightarrow\infty \\) 인 경우 충분통계 식은 \\( E[{\bf u}({\bf x})] \\) 가 된다.
    - 이미 원래 식에서도 \\( -\ln g({\bf \eta}) \\) 의 값이 \\( E[{\bf u}({\bf x})] \\) 였으므로 \\( \eta = \eta_{ML} \\) 로 생각하면 된다.
    
- 사실 충분 통계량은 베이지안 패러다임 관점과도 연관이 있지만 여기서는 설명하지 않도록 한다.
- 이는 8장에서 그래프 모델을 살펴보면서 확인을 하도록 하자.

- **참고** 
    - 이번 절에서는 \\( g({\bf \eta}) \\) 를 기준으로 수식을 전개하여 \\( (-\ln g({\bf \eta})) \\) 를 얻어냈으나 처음부터 이 식을 \\( G({\bf \eta}) \\) 정의하여 전개할 수도 있다. 
    - 다른 문서에서는 이렇게 전개하는 경우가 많더라.
    

## 2.4.2. 공액 사전 분포 (Conjugate priors)
- 앞서 여러 번 공액사전 분포(conjugate prior distribution)에 대해 이야기를 했었다.
- 예를 들면 베루누이 분포의 공액 사전 분포는 베타분포, 다항 분포의 공액 사전 분포는 디리슈레 분포라는 것을 확인했다.
- 가우시안의 경우는 평균에 대한 공액 사전 분포는 가우시안, 정확도(precision)에 대한 공액 사전 분포는 위샤트 분포이다.
- 이제 이번 절에서는 일반화된 지수족 분포 \\( p({\bf x}\|{\bf \eta}) \\) 에 대해서도 공액 사전 분포를 얻을 수 있는지 확인해 볼 것이다.
    - 공액적 관계에 놓이려면 사전 분포의 형태와 사후 분포의 형태가 같아야 한다.
    - 따라서 둘 다 지수족 분포에 속하는 형태를 고려한다.
    - 최종적으로 \\( p({\bf x}\|{\bf \eta}) \\) 에서 모수인 \\( {\bf \eta} \\) 에 대한 공액 사전 분포 \\( p({\bf \eta}) \\) 를 구해본다.

$$p({\bf \eta}|{\bf \chi}, v) = f({\bf \chi}, v)g({\bf \eta})^v \exp\{v{\bf \eta}^T{\bf \chi}\} \qquad{(2.229)}$$

- \\( f({\bf \chi}, v) \\) 는 정규화 계수이다.
- \\( g({\bf \eta}) \\) 는 앞서 사용된 식과 동일한 식으로 확률의 전체 합이 1이 되기 위한 계수이다.

- 실제 이를 이용해서 얻어지는 사후 확률 분포는 다음과 같다.

$$p({\bf \eta}|{\bf X}, {\bf \chi}, v) \propto g({\bf \eta})^{v+N}\exp\left\{ {\bf \eta}^T\left(\sum_{n=1}^{N}{\bf u}({\bf x})+v{\bf \chi}\right)\right\} \qquad{(2.230)}$$

- 형태를 잘 보면 사전 분포와 동일한 형태의 식이 된다는 것을 알 수 있다.
- 추가로 \\( v \\) 는 *effective number* 가 된다.
    - 앞서 설명을 했지만 이는 사전 확률 분포와 실제 발현된 데이터가 확률값에 미치는 영향력이 동일한 지점에서의 모수 값을 의미하게 된다.

## 2.4.3. 무정보적 사전 분포 (Noninfomative priors)
- 확률 추정의 문제에 있어서 어떤 경우에는 사전 분포의 모수 값을 손쉽게 지정할 수 있는 경우가 있다.
    - 예를 들어 모수의 값으로 그냥 0을 사용하면 된다거나 해도 무리가 전혀 없는 경우들
- 하지만 반대로 사전 분포의 형태를 전혀 예측하기 어려운 경우도 존재한다.
- 이 때 사용되는 분포가 무정보 사전 분포(non-infomative prior distribution)이다.
- 사실 이런 경우 가장 손쉬운 방법은,
    - \\( p(x\|\lambda) \\) 와 같이 모수 \\( \lambda \\) 가 주어지는 형태인 경우 \\( p(\lambda)=const \\) 로 결정하는 것이다.
    - 쉽게 말해 어떤 모수가 가질 값들이 모두 동일하다고 가정하는 것이다. 
        - \\( \lambda \\) 가 \\( K \\) 개의 상태를 가지는 이산(distrete) 변수라면 \\( 1/K \\) 를 \\( p(\lambda) \\) 의 확률 값으로 사용하면 된다.
    - 일견 타당해 보이는 방법이긴 하지만 수학적으로 문제가 되는 경우가 존재한다.

- \\( p(\lambda)=const \\) 로 가정했을 때의 문제
    - \\( \lambda \\) 의 범위가 unbounded 일 때
        - 만약 \\( \lambda \\) 가 몇 개의 상태를 가지게 되는지 모를 경우라면?
        - 단순한 상수 값을 사용하게 되면 분포를 전체 \\( \lambda \\) 영역에 대해 적분시 값이 \\( \infty \\) 가 되어버린다. 
            - 알다시피 확률 함수는 합이 1이 되어야 한다. 범위가 주어지지 않기 때문에 \\( \infty \\) 가 되어버린다.
        - 이런 경우를 **Improper prior** 라고 부른다.
        - 물론 Improper prior 라고 해서 마냥 쓸모 없는 것은 아니다. 
            - 이런 분포를 사용하더라도 실제 사후 확률 분포가 이런 사전 분포와 잘 결합하여 최종적으로 proper 한 분포가 될 수도 있기 때문이다. 
             - 물론 수학적으로 실제 이렇게 되는지 확인을 해봐야 한다.
            - 예를 들어 가우시안 분포의 평균 파라미터에 대해 상수 값의 사전 분포를 사용한다고 하더라도 실제 사후 분포는 문제가 없다.
    - 비선형적으로 변환되는 변수를 분포에 적용할 때 (밀도 변환 문제)
        - 조금 어려운 문제이긴 한데, 보통 확률 분포는 어떤 랜덤 변수를 입력 값으로 받아 분포의 결과 값을 반환하게 된다.
        - 이 때 변환에 대해서도 확률 함수에 대한 성질이 잘 들어맞아야 한다.
        - 만약 \\( h(\lambda)=const \\) 라고 하자. 이런 경우 \\( \lambda=\eta^2 \\) 이라고 하면 \\( h(\eta^2) \\) 또한 상수이다.
        - 이를 새로운 함수로 정의해서 \\( \widehat{h}(\eta)=h(\eta^2) \\) 이라고 하자. 이러면 \\( \widehat{h}(\eta) \\) 또한 상수 함수가 된다.
        - 이런 자연스러운 변환이 확률 식에도 통용이 될까?
        - 이제 어떤 확률 함수를 정의한다. \\( p_{\lambda}(\lambda)=const \\) 이다. 이를 \\( \eta \\) 에 대한 식으로 전개해보자.
            - 아래 식을 보면 알겠지만 \\( \lambda \\) 에 대해 상수였던 확률이 \\( \eta \\) 에 대해서는 선형 함수(1차원의 선형함수)로 전환된다.
            - 혹시 아래와 같이 확률 식이 전환되는 이유가 궁금하다면 식 1.27을 참고하도록 하자.

$$p_{\eta}(\eta)=p_{\lambda}(\lambda)\left|\frac{d\lambda}{d\eta}\right|=p_{\lambda}(\eta^2)2\eta \propto \eta \qquad{(2.231)}$$

- 여기서 하고자 하는 이야기는 명확하다. 
    - 상수 값을 가지는 사전 분포를 사용하는 것이 나쁜 선택은 아니지만 상황에 맞도록 사용해야 한다.
    - 어떤 경우에는 전혀 엉뚱한 결과를 초래할 수 있으므로 신중을 기할 것

- 이제 무정보적 사전 분포에 대한 2가지 예를 살펴볼 것이다.

-----

**예제 1 : Local parameter**

$$p(x|\mu) = f(x-\mu) \qquad{(2.232)}$$

- 이러한 파라미터 \\( \mu \\) 를 지역 파라미터 (location paramter)라고 부른다.
- 이런 형태의 밀도 함수를 가지는 형태를 **translation invariance** 만족한다고 하는데 아래와 같은 성질이 만족하기 때문이다.
- \\( \widehat{x}=x+c \\) 인 경우 \\( \widehat{\mu}=\mu+c \\) 가 성립

$$p(\widehat{x}|\widehat{\mu})=f(\widehat{x}-\widehat{\mu}) \qquad{(2.233)}$$

- 즉, 밀도의 모양이 동일한 형태로 유지되고 이동만 되는 형태.
    - \\( x \\) 가 \\( c \\) 만큼 이동하면 \\( \mu \\) 도 알아서 \\( c \\) 만큼 이동
    - 어떠한 위치에 있던지 확률 밀도의 값이 동일해져야 한다.

- 사전 분포 정하기
    - 사전 분포를 적용한 뒤에도 *translation invariance*  속성이 유지되어야 한다.
    - 즉, \\( A \le \mu \le B \\) 의 범위가 \\( A-c \le \mu \le B-c \\) 로 이동해도 같은 밀도 함수 값이 나와야 한다.

$$\int_{A}^{B}p(\mu)d\mu = \int_{A-c}^{B-c}p(\mu)d\mu = \int_{A}^{B}p(\mu-c)d\mu \qquad{(2.234)}$$

- 위의 식이 항상 성립하려면 다음 조건이 만족되어야 한다.

$$p(\mu-c)=p(\mu) \qquad{(2.235)}$$

- 이 말은 결국 \\( p(\mu)=const \\) 라는 의미가 된다.
- *translation invariance*  속성을 만족하는 \\( p(x\|\mu) \\) 분포에 대해서는 사전 분포로 상수 값을 가지는 분포를 사용하면 된다.

- 가우시안 분포에서의 무정보적 사전 분포의 사용
    - 가우시안 분포에서 평균 파라미터를 살펴보면, *translation invariance* 속성을 만족한다는 것을 알 수 있다.
    - 모양을 이동해도 중앙에 평균이 온다는 것은 자명한 사실. 평균 값은 local parameter 이다.
    - 정규 분포를 공액 사전 분포로 사용한다고 해보자. \\( p(\mu\|\mu\_0, \sigma\_0^2) = N(\mu\|\mu\_0, \sigma\_0^2) \\)
    - 이 때 \\( \sigma_0^2\rightarrow\infty \\) 로 하면 사후 확률 분포의 평균 값은 \\( \mu\_{N\rightarrow\infty}=\mu\_{ML} \\) 이 된다. (식 2.141 참고)
    - 이러면 사전 분포의 영향력이 0가 된다. 이것이 무정보적 사전 분포.
    - 그냥 간단하게 상상을 해봐도 가우시안 분포에서 \\( \sigma^2\rightarrow\infty \\) 이면 종 모양이 점점 옆으로 퍼지면서 직선의 형태가 될 것임.

-----

**예제 2 : Scale parameter**
- 확률 밀도가 다음을 만족한다고 하자.

$$p(x|\sigma)=\frac{1}{\sigma}f\left(\frac{x}{\sigma}\right) \qquad{(2.236)}$$

- 여기서 \\( \sigma>0 \\) 이다. 이 때의 \\( \sigma \\) 파라미터를 **scale parameter** 라고 한다.
- \\( \widehat{x}=cx \\) 이고, \\( \widehat{\sigma}=c\sigma \\) 일 때 다음을 만족한다면,

$$p(\widehat{x}|\widehat{\sigma})=\frac{1}{\widehat{\sigma}}f\left(\frac{\widehat{x}}{\widehat{\sigma}}\right) \qquad{(2.237)}$$

- 이를 **scale invariance** 를 만족한다고 한다.

- 사전 분포 정하기
    - local parameter 와 유사하게 사전 분포를 적용후에도 이 속성을 만족시키려면,
    - 사전 분포를 적용한 뒤에서 scale invarience 속성이 계속 유지되어야 한다.
    - 이 의미는 \\( A \le \sigma \le B \\) 일 때 \\( A/c \le \sigma \le B/c \\) 를 만족해야 한다는 것이다.

$$\int_{A}^{B}p(\sigma)d\sigma = \int_{A/c}^{B/c}p(\sigma)d\sigma = \int_{A}^{B}p\left(\frac{1}{c}\sigma\right)\frac{1}{c}d\sigma \qquad{(2.238)}$$

- 따라서 위의 식이 항상 성립해야 한다.
- 이를 정리하면 다음과 같다.

$$p(\sigma) = p\left(\frac{1}{c}\sigma\right)\frac{1}{c} \qquad{(2.239)}$$

- 이러한 조건을 만족하기 위해서는 \\( p(\sigma) \propto 1/\sigma \\) 여야 한다.
    - \\( f(\sigma) = K/\sigma \\) 로 해서 대입해보면 성립함을 알 수 있다.
- 스케일 파라미터의 경우 사전 분포로 \\( 1/\sigma \\) 를 사용하면 된다.
- 또한 \\( p(\sigma) \\) 또한 전체 적분 값에 대해서는 발산하므로 improper prior 임을 알 수 있다.

- 한 가지 재미난 사항을 언급하고 넘어가도록 하자.
    - 보통 scale 파라미터의 경우 로그( \\( \ln(\cdot) \\) )를 적용하여 사용하는 것이 더 편리할 때가 있는데,
    - 다음과 같은 이유이다.
        - \\( x=g(\sigma)=\ln(\sigma) \\) 라고 하면

$$p_{\sigma}(\sigma) = p_x(x)\left|\frac{dx}{d\sigma}\right|=p_x(g(\sigma))|g'(\sigma)|=p_x(\ln(\sigma))\cdot\frac{1}{\sigma} \propto p_x(\ln(\sigma))p_{\sigma}(\sigma)$$

- 결국 \\( p_x(\ln(\sigma)) = const \\) 라는 결과를 얻게 된다.

$$\begin{array}{llc}\sigma & \ln\sigma & range \\
1\le\sigma\le 10 & 0 \le \ln\sigma \le \ln 10 & \ln 10 \\
10\le\sigma\le 100 & \ln 10 \le \ln\sigma \le 2\ln 10 & \ln 10 \\
100\le\sigma\le 1000 & 2\ln 10 \le \ln\sigma \le 3\ln 10 & \ln 10 \end{array}$$

- 위의 표를 표면 \\( \ln \\) 함수를 사용하는 경우 범위의 간격이 동일해진다는 것을 알 수 있다.
- 즉, 각 범위에서의 밀도 값도 같아진다.
- 따라서 스케일 파라미터의 경우 \\( ln \\) 를 이용하여 변환된 밀도 함수를 계산하는게 실제 계산에 더 편리한 경우가 많다.

- 가우시안 분포에서의 무정보적 사전 분포의 사용
    - 평균값에 대한 무정보적 사전 분포를 확인했던 것과 마찬가지로, 분산값에 대한 무정보적 사전 분포를 고려해 볼 수 있는데
    - 이 때 분산이 바로 스케일 파라미터 속성을 만족한다.
    - 우선 평균에 대해 \\( \tilde{x}=x-\mu \\) 를 적용하고 이를 스케일 파라미터인 분산값에 대해 전개하면

$$N(x|\mu, \sigma^2) \propto \sigma^{-1}\exp\{-(\tilde{x}/\sigma)^2\} \qquad{(2.240)}$$

- 앞서 이야기한대로 수식을 전개할 때에는 \\( \lambda=1/\sigma \\) 인 정확도(precision)로 표현하는게 더 편하다.
- \\( p(\sigma) \propto 1/\sigma \\) 는 \\( p(\lambda) \propto 1/\lambda \\) 이므로 무리없게 전개되고, 공액 사전 분포인 감마(Gamma) 사전 분포가 비정보적 사전 분포가 되려면,
    - 사후분포에 대해 사전 분포의 영향력이 없어야 한다.
    - 따라서 사전 분포 \\( Gam(\lambda\|a\_0, b\_0) \\) 에서 \\( a\_0=b\_0=0 \\) 이어야 한다.
    
