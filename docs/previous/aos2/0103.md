---
layout: page-sidenav
group: "Models, Statistical Inference and Learning"
title: "3. Fundamental Concepts in Inference"
---

- 상당수의 추론 문제는 estimation, confidence sets, hypothesis testing 으로 구분할 수 있다
- `Notation` : Parametric model \\( \mathfrak{F} = \\{ f(x;\theta):\theta\in\theta \\} \\) 에 대해, 확률 또는 기대값의 밑첨자로 \\( \theta \\) 가 사용되는 경우 \\( f(x;\theta) \\) 를 밀도함수로 사용하는 \\( x \\) 대한 적분으로 간주한다 (절대 \\( \theta \\) 에 대한 적분이 아님). 가령 다음과 같은 방식으로 표기한다:

$$
\mathbb{P}_{\theta}(X\in A) = \int_{A} f(x;\theta)dx,\quad \mathbb{E}_{\theta}(r(X)) = \int r(x)f(x;\theta)dx
$$

$$
\mathbb{V}_{\theta}(g(X)) = \int |g(x)|^{2} f(x;\theta)dx-\left(\int g(x)f(x;\theta)dx \right)^{2}
$$

## Point estimation

- 점추정(point estimation)은 어떤 대상의 양(quantity)을 "best guess" 하나로 추정하는 걸 말한다
- 점추정은 다양한 대상을 가지고 적용할 수 있는데 가령 parametric model \\( \mathfrak{F} \\) 의 parameter 나, CDF \\( F \\), PDF \\( f \\), regression function \\( r \\), prediction 에서 \\( Y \\) 의 값 등이 될 수 있다
- 앞으로 unknown parameter \\( \theta \\) 에 대한 점추정은 $$ \hat{\theta} $$ 또는 $$ \hat{\theta}_{n} $$ 으로 표기한다. $$ \hat{\theta} $$ 은 데이터에 따라 달라질 수 있으므로 확률변수이다
- 점추정은 수학적으로는 다음과 같이 쓸 수 있다. 분포 \\( F \\) 에서 [i.i.d](https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables) 로 추출된 \\( n \\) 개의 데이터 \\( X_{1},\ldots, X_{n} \\) 가 있다고 했을 때, parameter \\( \theta \\) 의 점추정 $$ \hat{\theta}_{n} $$ 은 \\( X_{1},\ldots, X_{n} \\) 에 대한 함수이다:

$$
\hat{\theta}_{n} = g(X_{1},\ldots, X_{n})
$$

- 점추정에 대한 Bias 는 다음과 같이 정의한다 (위의 `Notation` 참조)

$$
\text{bias}(\hat{\theta}_{n})=\mathbb{E}_{\theta}(\hat{\theta}_{n})-\theta = \int \hat{\theta}_{n}(x) f(x;\theta)dx-\theta
$$

- 만약 $$ \text{bias}(\hat{\theta}_{n}) = 0 $$ 이라면 (즉, $$ \mathbb{E}_{\theta}(\hat{\theta}_{n}) = \theta $$ ) 우리는 $$ \hat{\theta}_{n} $$ 이 **불편향(unbiased)** 되었다고 말한다
- 불편향성은 과거만큼 중요하게 여기지 않는다. 왜냐하면 실제로 자주 사용되는 추정량(estimator)들은 대체로 편향되어 있기 때문이다. 그 대신 데이터를 모을수록 (즉, \\( n \to \infty \\) 일수록) $$ \hat{\theta}_{n} $$ 이 원래의 true parameter $$ \theta $$ 로 [확률수렴(converge in probability)](https://en.wikipedia.org/wiki/Convergence_of_random_variables#Convergence_in_probability)하는 성질은 가지길 원한다. 이 성질을 일치성(consistency) 이라 한다

---

`Definition 1`. Parameter \\( \theta \\) 의 점추정 \\( \hat{\theta}_{n} \\) 이 \\( \theta \\) 로 확률수렴(converge in probability)하면 **일치성(consistency)** 을 가진다고 말한다

---

- 추정량 $$ \hat{\theta}_{n} $$ 의 분포를 **표본분포(sampling distribution)** 라 부른다. $$ \hat{\theta}_{n} $$ 의 표준편차(standard deviation) 을 **표준오차(standard error)** 라 하고 \\( \text{se} \\) 로 표기한다 :

$$
\text{se}(\hat{\theta}_{n})=\sqrt{\mathbb{V}_{\theta}(\hat{\theta}_{n})} = \sqrt{\int |\hat{\theta}_{n}(x)|^{2}F(dx)-\left(\int \hat{\theta}_{n}(x)F(dx) \right)^{2}}
$$

- 표준오차 \\( \text{se} \\) 는 CDF \\( F \\) 에 대한 statistical functional 이므로 사실 unknown quantity 지만 추정이 가능하다. 표준오차 \\( \text{se} \\) 의 추정량을 \\( \hat{\text{se}} \\) 이라 한다

- `Example`. \\( X_{1},\ldots, X_{n} \\) 이 모수 $$ p $$ 인 베르누이 분포를 따른다고 하고 $$ \hat{p}_{n} = \frac{\sum_{i}X_{i}}{n} $$ 라 하자. 이 경우 $$ \mathbb{E}(\hat{p}_{n}) = \frac{\sum_{n}\mathbb{E}(X_{i})}{n} = \frac{np}{n}=p $$ 이므로 점추정 $$ \hat{p}_{n} $$ 은 unbiased 이다. 또한 [Law of large numbers](https://en.wikipedia.org/wiki/Law_of_large_numbers#Strong_law) 에 의해 $$ \hat{p}_{n} $$ 은 $$ p $$ 로 almost surely 수렴한다. 표준오차와 표준오차의 추정량은 다음과 같다 [(증명참조)](https://sungbinlim.github.io/sl/proof/aos2/010301.pdf) :

$$
\text{se} = \sqrt{\mathbb{V}(\hat{p}_{n})} = \sqrt{\frac{p(1-p)}{n}}
$$

$$
\hat{\text{se}}=\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}
$$

- 점추정 $$ \hat{\theta}_{n} $$ 의 quality 는 아래와 같이 정의되는 **MSE(mean squared error)** 또는 $$ L_{2} $$-loss 를 측정함으로써 평가할 수 있다 :

$$
\text{MSE} = \mathbb{E}_{\theta}(\hat{\theta}_{n}-\theta)^{2}\quad \cdots \quad (1)
$$

- 식 (1) 에서 기대값 $$ \mathbb{E}_{\theta}(\cdot) $$ 의 density function $$ f_{\theta}(x_{1},\ldots, x_{n}) $$ 은 i.i.d. 가정에 의해 다음과 같이 product 형태로 쓸 수 있다 :

$$ 
f(x_{1},\ldots, x_{n};\theta) = \prod_{i=1}^{n}f(x_{i};\theta )
$$

- 다음 `Theorem 1` 에 의해 MSE 는 $$ \text{bias} $$ 와 $$ \mathbb{V}_{\theta}(\hat{\theta}_{n}) $$ 으로 분해할 수 있다

---

`Theorem 1`. 

$$
\text{MSE} = \text{bias}^{2}(\hat{\theta}_{n}) + \mathbb{V}_{\theta}(\hat{\theta}_{n})
$$

---

`Theorem 2`. 만약 $$ n\uparrow\infty $$ 일 때 $$ \text{bias} $$ 와 $$ \text{se} $$ 모두 0 으로 수렴한다면 점추정 $$ \hat{\theta}_{n} $$ 은 일치성을 가진다 :

$$
\hat{\theta}_{n} \overset{p}{\rightarrow} \theta
$$

---
 
- `Theorem 2` 에서 $$ \hat{\theta}_{n} $$ 은 $$ \theta $$ 로 $$ L_{2} $$-수렴하므로 확률수렴보다 더 강한 수렴성을 가진다
- `Example` 의 베르누이 분포의 예제에서 위 `Theorem 2` 의 결과로 설명할 수 있다

---

`Definition 2`. 추정량 $$ \hat{\theta}_{n} $$ 이 다음을 만족하면 **asymptotically normal** 이라 한다 :

$$
\frac{\hat{\theta}_{n}-\theta}{\text{se}} \rightsquigarrow \mathcal{N}(0,1)
$$

위에서 $$ \rightsquigarrow $$ 는 [분포수렴(converge in distribution)](https://en.wikipedia.org/wiki/Convergence_of_random_variables#Convergence_in_distribution) 을 의미한다

---

## Confidence Sets

- Parameter $$ \theta $$ 에 대한 $$ (1-\alpha) $$-**신뢰구간(confidence interval)** 은 아래 식 (2) 를 만족하는 구간 $$ C_{n} = (a_{n},b_{n}) $$ 으로 정의된다. 여기서 $$ a_{n} = a(X_{1},\ldots, X_{n}) $$, $$ b_{n} = b(X_{1},\ldots, X_{n}) $$ 은 데이터 $$ X_{1},\ldots,X_{n} $$ 에 대한 함수이다. 식 (2)는 신뢰구간 $$ C_{n} $$ 이 (적어도) $$ (1-\alpha) $$ 의 확률로 $$ \theta $$ 를 잡는다(trap)는 의미이다 :

$$
\mathbb{P}_{\theta}(\theta \in C_{n}) \geq 1-\alpha,\quad \forall \theta \in \Theta\quad\cdots\quad (2)
$$

- `Warning` 식 (2)는 $$ \theta $$ 의 **확률에 관한 명제(probability statement)** 가 아니다. 신뢰구간을 이해할 때 가장 많이 혼동하는 부분인데, 신뢰구간 $$ C_{n} $$ 이 데이터에 따라 랜덤하게 바뀌는 집합이고 $$ \theta $$ 는 확률변수가 아니라 고정된 값이다.  즉, $$ \theta $$ 가 $$ (1-\alpha) $$ 확률로 신뢰구간에 속하는게 아니라, 우리가 산출한 신뢰구간이 $$ (1-\alpha) $$ 확률로 $$ \theta $$ 를 잡는 것이다 

![figure1.1]({{ site.baseurl }}/images/aos2_Figure010301.png){:class="center-block" height="200px"}

- 만약 $$ \theta $$ 가 벡터인 경우 우리는 신뢰구간 대신 일반적으로 **신뢰집합(confidence set)** 이란 용어를 쓴다

- 보통 신뢰구간(95%)을 해석할 때 같은 실험(experiment)을 반복해서 시행하는 경우, 산출한 신뢰구간들의 95% 가 parameter $$ \theta $$ 를 포함하는 개념으로 이해한다. 이것도 틀린 말은 아니지만, 실제로 실험을 그만큼 많이 시행하는 건 아니기 때문에 유용한 해석은 아니다. 보다 나은 해석은 아래와 같은 방식이다 :
	- 첫째날엔 parameter $$ \theta_{1} $$ 에 대한 95% 신뢰구간을 구한다. 다음날엔 새로운 데이터를 모아 $$ \theta_{1} $$ 과 관계없는 $$ \theta_{2} $$ 의 95% 신뢰구간을 구한다. 셋째날에도 마찬가지로 새로운 데이터를 가지고 전혀 관계없는 $$ \theta_{3} $$ 의 95% 신뢰구간을 구한다. 이런식으로 서로 관계없는 parameter $$ \theta_{1}, \theta_{2}, \ldots, $$ 에 대한 신뢰구간을 연속해서 100개 정도 만들었을 때, 이 중 95개의 구간들이 true parameter 를 잡을 것이다

- "식 (2)는 $$ \theta $$ 의 확률에 관한 명제가 아니다" 라는 말이 혼동스러운 사람은 아래 Berger $$ \& $$ Wolpert (1984)의 예제를 읽어보자
 
---

`Example` parameter $$ \theta $$ 를 고정하고 확률변수 $$ X_{1}, X_{2} $$ 가 서로 독립이고 $$ \mathbb{P}(X_{i} = 1) = \mathbb{P}(X_{i} = -1) = 1/2 $$ 인 분포를 가진다고 하자. 우리는 $$ X_{1}, X_{2} $$ 를 직접 관찰할 수 없고, 간접적으로 $$ Y_{i} = X_{i} + \theta $$ 만 관찰할 수 있다고 가정하자. 이 때 집합 $$ C $$ 를 다음과 같이 정의한다 :

$$
C = \begin{cases} \{Y_{1} - 1\} & : Y_{1} = Y_{2} \\ \{(Y_{1}+Y_{2})/2\}& : Y_{1}\neq Y_{2} \end{cases}
$$

주어진 $$ \theta $$ 가 얼마든간에 $$ X_{1} = X_{2} = -1 $$ 인 경우를 제외하고 항상 $$ \theta \in C $$ 이다. 즉 $$ \mathbb{P}_{\theta}(\theta \in C) = 3/4 $$ 이므로 집합 $$ C $$ 는 75% 신뢰구간이다. 

만일 우리가 $$ Y_{1} = 15, Y_{2} = 17 $$ 이라는 데이터를 관찰했다고 하자. 이 때 신뢰구간 $$ C $$ 는 단일원소집합(singleton) $$ \{ 16 \} $$ 이 된다. 앞에서 설명했듯 $$ C $$ 는 75% 확률로 $$ \theta $$ 를 잡는다. 하지만 우리는 이미 $$ C $$ 를 정의할 때, $$ Y_{1} \neq Y_{2} $$ 이면 $$ (Y_{1}+Y_{2})/2 = [(\theta + 1) + (\theta - 1)]/2= \theta $$ 가 된다는 걸 알고 있으므로 $$ \theta = 16 $$ 으로 확신할 수 있다. 다시 말해 $$ \mathbb{P}(\theta \in \{ 16 \} \vert Y_{1} = 15, Y_{2} = 17) = 1 $$ 이다. 집합 $$ C $$ 는 분명히 75% 신뢰구간이지만, 이는 데이터 $$ X_{1}, X_{2} $$ 가 임의로 주어지기 때문이다

--- 

- [베이지안 추론(Bayesian inference)](https://sungbinlim.github.io/sl/docs/aos2/0600) 에선 $$ \theta $$ 가 고정된 숫자가 아닌 확률변수인 경우를 상정한다. 이 때는 $$ \theta $$ 에 대한 probability statement 를 다룰 것이다. 그러나 베이지안 추론에서 다루는 베이지안 구간(Bayesian interval) 은 [degree-of-belief](https://en.wikipedia.org/wiki/Subjectivism#In_probability) 확률로 해석해야 한다.

---

`Theorem 3`. (Normal-based Confidence Interval) $$ \hat{\theta}_{n} \approx \mathcal{N}( \theta, \hat{\text{se}}^{2} ) $$ 라고 가정하자. $$ \Phi $$ 를 표준정규분포의 CDF, $$ z_{\alpha/2} = \Phi^{-1}(1-\frac{\alpha}{2}) $$ 라 하자. 이 때 $$ C_{n} $$ 을 다음과 같이 정의하자 :

$$
C_{n} = (\hat{\theta}_{n} - z_{\alpha/2}\hat{\text{se}}, \hat{\theta}_{n} + z_{\alpha/2}\hat{\text{se}})
$$

이 때, 다음이 성립한다:

$$
\mathbb{P}_{\theta}(\theta \in C_{n})\to 1-\alpha
$$

