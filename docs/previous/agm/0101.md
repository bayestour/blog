---
layout: page-sidenav
group: "GAN"
title: "1. Introduction"
---


- [GAN (Goodfellow *et al*, 2014)](https://arxiv.org/abs/1406.2661) 논문 요약 설명
- Minimax game 을 토대로 한 generative model (이하 **GM**) 을 이해한다

### 미리 알아두면 좋은 용어들

- [Minimax Game](https://en.wikipedia.org/wiki/Minimax)
- [Nash Equilibrium](https://en.wikipedia.org/wiki/Nash_equilibrium)
- [Saddle Point](https://en.wikipedia.org/wiki/Saddle_point)
- [Change of variable formula](https://math.stackexchange.com/questions/152338/is-there-a-change-of-variables-formula-for-a-measure-theoretic-integral-that-doe)

---
## What is GAN? 
- GAN 은 GM 의 한 종류 (GM 의 분류는 [Preface](https://sungbinlim.github.io/sl/docs/agm/0) 참조)
- GAN 은 

#### GAN 의 알려진 장점

1. GAN 은 sample 을 parallel 하게 생성할 수 있으므로 \\( \mathbf{x} = (x_{1},\ldots,x_{n})\\) 의 dimension \\(n\\) 에 비례해서 런타임이 증가하는 Fully Visible Belief Network (**FVBN**) 보다 빠르다. 
2. Boltzmann machine (**BM**) 이나 Nonlinear Independent Component Analysis (**ICA**) 에 비해 Generator function 에 거의 제약을 걸지 않는다. 
3. Markov chain 을 쓰지 않는다. 
4. Variational bound 이나 특정 model family (e.g. mean-field family) 를 쓰지 않는다. GAN 은 asymptotically consistent 하다. 이는 Variational Auto-Encoder (**VAE**) 에 비해 확실한 장점이다.
	- Asymptotically consistency 에 대해선 Proposition 2 를 참조한다
5.


$$
V(D,G) = \mathbb{E}_{x\sim p_{\text{data}}(x)}[\log D(x)]+\mathbb{E}_{z \sim p_{Z}(z)}[\log (1-D(z))]
$$

GAN 은 위의 \\(V(D,G)\\) 를 이용하여 [최소-최대 문제](https://en.wikipedia.org/wiki/Minimax) 를 푸는 것을 목적으로 한다

$$
\min_{G}\max_{D} V(D,G)
$$

---

### Proposition 1
*For \\(G\\) fixed, the optimal discriminator \\(D\\) is*

$$
D_{G}^{*}(x)=\frac{p_{\text{data}}(x)}{p_{\text{data}}(x)+p_{g(Z)}(x)}
$$

*Proof*. \\(V(D,G)\\) 를 적분형식으로 풀어 쓰면 아래와 같다

$$
V(D,G) = \int_{\mathcal{X}}p_{\text{data}}(x)\log(D(x))dx+\int_{\mathcal{Z}}p_{Z}(z)\log(1-D(g(z)))dz\qquad \cdots(1)
$$

식 (1) 의 우변 두 번째 적분항은 *Change of variable formula* (**c.v.f**) 에 의해 아래와 같이 바꿀 수 있다. (편의를 위해 임시로 \\(Y:= g(Z)\\) 를 정의한다. 여기서 \\( Z:\Omega \to \mathcal{Z}\\), \\(g:\mathcal{Z}\to\mathcal{X}\\) 이므로 \\(Y:\Omega \to \mathcal{X}\\) 이다)

$$
\begin{aligned}
\int_{\mathcal{Z}}p_{Z}(z)\log(1-D(g(z)))dz &=\int_{\Omega}\log(1-D(g(Z(\omega))))\mathbb{P}(d\omega)\qquad (\because \text{c.v.f})
\\ \\ &= \int_{\Omega}\log(1-D(Y(\omega)))\mathbb{P}(d\omega)\qquad (\because Y=g(Z))
\\ \\ &= \int_{\mathcal{X}}p_{Y}(x)\log (1-D(x))dx\qquad (\because \text{c.v.f})
\\ \\ &= \int_{\mathcal{X}}p_{g(Z)}(x)\log (1-D(x))dx\qquad (\because Y=g(Z))
\end{aligned}
$$

따라서 식 (1) 을 아래와 같이 정리할 수 있다

$$
V(D,G) = \int_{\mathcal{X}}\left[p_{\text{data}}(x)\log(D(x))+p_{g(Z)}(x)\log (1-D(x))\right]dx
$$

이제 위의 식을 maximize 하는 \\( D \\) 를 찾아야 한다. 

$$
\sup_{f\in\mathcal{M}}\int_{\mathcal{X}} f(x)d\mu=\int_{\mathcal{X}}\sup_{f\in\mathcal M}f(x)d\mu
$$

위의 적분식을 살펴보자. \\(p_{\text{data}}(x)\\) 는 타겟 분포이므로 \\(D\\) 에 따라 변하지 않고, 가정에서 \\(G\\), 즉 \\(g(Z)\\) 라는 확률변수와 그 분포는 고정된 것으로 가정하고 있다. 그러므로 위의 식을 \\(D\\) 에 대해 maximize 하려면 \\( \int_{\mathcal{X}}\cdots \\) 안의 적분항을 maximize 해야 한다. 

그러므로 위 보조정리에 의해

$$
\arg\max_{D(x)}\left[p_{\text{data}}(x)\log(D(x))+p_{g(Z)}(x)\log (1-D(x))\right] = \frac{p_{\text{data}}(x)}{p_{\text{data}}(x)+p_{g(Z)}(x)}
$$

Q.E.D



### Proposition 2

*If \\(G\\) and \\(D\\) have enough capacity, and at each step of Algorithm 1, the discriminator is allowed to reach its optimum given \\(G\\), and \\(p_{g}\\) is updated so as to improve the criterion*

$$
\mathbb{E}_{x\sim p_{\text{data}}}[\log D_{G}^{*}(x)]+\mathbb{E}_{x\sim p_{g}}[\log(1-D_{G}^{*})(x)]
$$

*then \\(p_{g}\\) converges to \\(p_{\text{data}}\\)*

*Proof*. 생략

---

---

## GAN 구현시 발생하는 문제점
### Adversarial training 에서 주의할 점
- Saddle point 가 나올 때 주의해야 한다


---
#
### 참고자료

- [2016 NIPS Tutorial: Generative Adversarial Networks](https://arxiv.org/abs/1701.00160)
- [](https://anujdutt9.github.io/GAN-PI.html)
- [유재준님 블로그](http://jaejunyoo.blogspot.com/2017/01/generative-adversarial-nets-1.html#more)