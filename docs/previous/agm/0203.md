---
layout: page-sidenav
group: "VAE"
title: "3. ELBO"
---

- ELBO (**E**vidence **L**ower **Bo**und) 는 VAE 에서의 objective function 이다

$$
\mathcal{L}_{\theta,\phi}(x)=\mathbb{E}_{q_{\phi}(z|x)}\left[\log p_{\theta}(x,z)-\log q_{\phi}(z \vert x)\right]
$$

- ELBO 라는 이름은 evidence (또는 marginal likelihood) $$ \log p_{\theta}(x) $$ 의 **하한(lower bound)** 이기 때문에 주어진 이름이다

$$
\mathcal{L}_{\theta,\phi}(x)=\log p_{\theta}(x)-\mathbb{KL}(q_{\phi}(z \vert x)\Vert p_{\theta}(z \vert x)) \leq \log p_{\theta}(x)
$$

- ELBO 를 optimize 하려면 두 개의 gradient 를 구해야한다:

	- GM 의 parameter $$ \theta $$ 에 대한 gradient $$ \nabla_{\theta} $$ 
	- Variational parameter $$ \phi $$ 에 대한 gradient $$ \nabla_{\phi} $$ 

- 첫번째 gradient $$ \nabla_{\theta} $$ 를 구하는 건 어렵지 않다. 기대값 계산에 사용되는 확률밀도함수 $$ q_{\phi} $$ 가 $$ \theta $$ 랑 상관없는 함수이므로 그냥 기대값에 집어넣으면 된다. 이 때 $$ -\log q_{\phi}(z \vert x) $$ 도 같이 날라간다 :smile:

$$
\begin{aligned}
\nabla_{\theta} \mathcal{L}_{\theta,\phi}(x)  &= \nabla_{\theta}\mathbb{E}_{q_{\phi}(z|x)}\left[\log p_{\theta}(x,z)-\log q_{\phi}(z|x)\right] \\
& = \mathbb{E}_{q_{\phi}(z|x)}\left[\nabla_{\theta}\log p_{\theta}(x,z)\right]
\end{aligned}
$$

- 문제는 (항상) 둘째(?)다. 이번에는 $$ \nabla_{\phi} $$ 가 아예 $$ \phi $$ 를 미분하는 연산자이므로 $$ q_{\phi} $$ 도 같이 미분해줘야 한다. 그러므로 기대값에 미분연산을 집어넣으면 큰일난다 :angry: 

$$
\begin{aligned}
\nabla_{\phi} \mathcal{L}_{\theta,\phi}(x)  &= \nabla_{\phi}\mathbb{E}_{q_{\phi}(z \vert x)}\left[\log p_{\theta}(x,z)-\log q_{\phi}(z \vert x)\right] \\
& \neq \mathbb{E}_{q_{\phi}(z \vert x)}\left[\nabla_{\phi}\log p_{\theta}(x,z)-\nabla_{\phi}\log q_{\phi}(z \vert x)\right]
\end{aligned}
$$

- 이걸 해결하기 위해 등장한 방법이 바로 지금부터 소개할 Reparametrization trick 이다