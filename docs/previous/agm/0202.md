---
layout: page-sidenav
group: "VAE"
title: "2. Variational Bayes"
---

## Variational Method

- Variational 이란 이름은 **변분법(variational method)** 에서 따온 이름이다. 특정 문제를 풀 목적으로 **연산자(operator)** 를 최적화(optimize)하는 방법론을 통칭한다 (뭐...뭐? :fearful:)
- 연산자는 함수를 변수로 가지는 함수이다 (그럼 연산자를 변수로 가지는 함수는? :thinking:). 참고로 범함수(functional)는 target space 가 $$ \mathbb{R} $$ 이거나 $$ \mathbb{C} $$ 인 연산자를 말한다
- 함수를 변수로 가진다는 것은 어떤 의미일까? 가령 다음과 같은 적분 연산자(integral operator)는 함수를 값으로 보내는 범함수에 해당한다

$$
\mu : f \mapsto\int xf(x)dx
$$

- 만일 $$ f $$ 를 확률밀도함수 중에서 뽑는다고 하면, 위 적분 연산자는 확률분포에 따라 기대값을 계산한다. 즉, [통계적 범함수](https://sungbinlim.github.io/sl/docs/aos2/0202) 가 된다
- `Example` 변분법을 이해하기 위해 목적함수(Objective function) 을 다음과 같이 설정해주자

$$
\mathcal{L}(f):=\int(x-\mu[f])^{2}g(x)dx,\quad \mu[f]:=\int xf(x)dx
$$

- 위 목적함수를 보면 분산이랑 비슷해보인다. 사실 위 목적함수는 bias-variance tradeoff 를 표현하는 목적함수이다

$$
\mathcal{L}(f)=\mathbb{V}_{X\sim g}[X]+ (\mu[f]-\mu[g])^{2}
$$

![figure1.1]({{ site.baseurl }}/images/agm_Figure020202.png){:class="center-block" height="300px"}

- 목표함수 $$ \mathcal{L} $$ 를 최소화하는 $$ f^{*} $$ 는 무엇일까?

$$
f^{*}:=\underset{f\in\mathfrak{F}}{\text{argmin }}\mathcal{L}(f)
$$

- 목표함수 $$ \mathcal{L}(f,g) $$ 안의 제곱을 전개하면 아래와 같이 정리된다

$$
\mathcal{L}(f,g)= (\mu[f]-\mu[g])^{2} + \sigma_{g}^{2}
$$

- 여기서 $$ \sigma_{g}^{2} $$ 는 $$ g $$ 가 확률밀도함수 일 때의 분산이다. $$ g $$ 는 현재 고정되어 있으므로 $$ \sigma_{g}^{2} $$ 는 상수이다. 그러므로 위 값을 최소화하려면 $$ \mu[f] = \mu[g] $$ 이어야 한다
	- 만약 $$ g\in\mathfrak{F} $$ 이면 $$ f^{*} = g $$ 를 선택하면 된다
	- 만약 $$ g\notin\mathfrak{F} $$ 이면 꿩 대신 닭으로 $$ \mu[f] = \mu[g] $$ 인 다른 $$ f $$ 를 고르면 된다
	- 그런 $$ f $$ 가 $$ \mathfrak{F} $$ 에 없다면 $$ (\mu[f] - \mu[g])^{2} $$ 가 최소인 $$ f $$ 를 찾아야 한다
- 이처럼 변분법 문제는 해(solution)를 **어떤 공간** 에서 찾을지가 큰 관건이다. 공간에 따라 해가 없거나 무수히 많거나 여러가지 경우가 가능하다
- 물리학을 잘 아는 사람은 [최단강하곡선(Brachistochrone curve)](https://en.wikipedia.org/wiki/Brachistochrone_curve) 문제를 잘 알 것이다. 이동시간을 최소로 만드는 곡선을 찾는 문제로 전형적으로 변분법의 문제가 되는 것이다
- 최단강하곡선에 대한 재미난 역사는 [링크](https://www.facebook.com/engineertoon/posts/484329528420574) 를 참조하자

![figure1.1]({{ site.baseurl }}/images/agm_Figure020201.gif){:class="center-block" height="300px"}


## Variational Bayesian Inference

- 위에서 소개한 변분법을 통계학에서 사용하면 어떨까?   :stuck_out_tongue_winking_eye:
- 우선 Bayesian Inference 의 과정이 무엇인진 간략하게 소개한다

1. 사전분포(Prior distribution) $$ p(\theta) $$ 를 고른다. Prior 는 데이터를 분석하기 전 패러미터의 분포에 대한 우리의 믿음(belief)을 나타낸다
2. 주어진 패러미터 $$ \theta$$ 로 statistical model $$ p(x\vert\theta) $$ 를 고른다. 이걸 Likelihood 라 부른다
3. 관찰된 데이터 $$ X_{1},\ldots, X_{n} $$ 를 가지고 사후분포(Posterior distribution) $$ p(\theta\vert x)$$ 를 구한다

$$
p(\theta\vert x) = \frac{p(x\vert\theta)p(\theta)}{\int p(x\vert\theta)p(\theta)d\theta}
$$

