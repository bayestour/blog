---
layout: post-sidenav
title: "소벨 테스트 완전히 이해하기 (2): 델타 메쏘드"
group: "Bayesian Statistics"
author: 박준석
---

전 포스팅에서 예고했듯 이번 글에서는 델타 메쏘드에 대해 설명하겠습니다. 델타 메쏘드는 소벨 테스트의 핵심이기 때문에, 이것을 이해하지 않고 지나간다는 것은 수박 겉핥기에 지나지 않습니다. 이것은 방법론의 "상자 안쪽"을 제대로 이해하고 지나가자는 제 생각과 배치되기 때문에, 짚고 넘어가도록 하겠습니다. 여기서는 확률변수가 한 개인 경우만 생각하지만, 여러 개인 경우에 대해서도 거의 비슷하게 적용 가능합니다.

가장 간단하게는 다음의 상황을 생각해 봅시다. 이를테면 \\(X \sim N(\mu, 1^2)\\), \\(\mu=2\\)라고 해 봅시다. \\(\mu\\)를 추정하는 것은 너무나 쉽습니다. 표본평균을 쓰면 되죠. 그런데 이런 욕망을 한 번쯤 가져 보시지 않았습니까? \\(\mu\\)의 변환된 값, 이를테면 \\(1/\mu\\)나 \\(\log(\mu)\\)를 추정하고 싶다는 생각 말입니다. 일견 표본평균을 써서 추정하면 될 것 같이 보입니다. 그러니까 \\(1/\bar{X}\\)나 \\(\log(\bar{X})\\)를 쓰는거죠. 그런데 이 값들이 평균적으로 참값과 일치할까요? 그리고 분산은 얼마나 될까요? 이런 것들은 X 자체의 분포로부터 알기 힘듭니다. 사실 많은 경우에 이들을 직접 구한다는 것 자체가 불가능합니다. 델타 메쏘드는 이런 상황에서 \\(1/\bar{X}\\)나 \\(\log(\bar{X})\\)와 같은 값의 분포를 유도할 수 있게 해 줍니다. [1]

델타 메쏘드를 적용하기 위해서는 중심극한정리가 적용될 수 있는 추정치가 하나 필요합니다. 정규분포의 경우, 표본평균에 중심극한정리가 적용된다는 것은 기본 상식입니다 (\\(\bar{X}_n\\)은 크기가 \\(n\\)인 샘플에서 계산된 표본평균을 의미합니다):

$$\bar{X}_n \sim N(\mu, \sigma^2/n) ... (1)$$

여기서 델타 메쏘드의 핵심은 다음과 같습니다. 한 번 미분가능하고, \\(g'(x) \neq 0\\)인 함수 \\(g\\)에 대해 다음이 성립합니다:

$$g(\bar{X}_n) \sim N(g(\mu), [g'(\mu)]^2\sigma^2/n) ... (2)$$

여기서 \\(g'(\mu)\\)는 \\(g\\)를 한 번 미분한 도함수에 \\(\mu\\)를 대입한 값을 의미합니다. 증명은 테일러전개에 의존하는데, 구체적인 것은 생략합니다. 자세한 것은 [2] 를 보세요.

(2)의 의미는 다음과 같습니다: \\(\mu\\) 대신 \\(g(\mu)\\)를 추정하려 할 때도 여전히 \\(g(\bar{X}_n)\\)을 추정치로 사용할 수 있습니다. 그리고 (큰 표본에서) 이것의 bias는 0입니다. 직관적으로 그럴듯하죠? \\(\mu\\)를 추정할 때 \\(\bar{X_n}\\)를 사용하는 것처럼, 이를테면 \\(1/\mu\\)를 추정할 때도 따로 추정치를 개발할 필요 없이 \\(1/(\bar{X_n})\\) 을 불편추정치로 사용할 수 있다는 것입니다. 여기서 \\(g(x) = 1/x\\) 인데, 이 함수는 미분가능한 함수 (다항함수) 니까 델타 메쏘드의 조건을 충족합니다. 

이제 분산 항을 보면, \\([g'(\mu)]^2 \sigma^2/n\\) 는 원래 추정치인 표본평균의 분산인 \\(\sigma^2/n\\) 에 \\([g'(\mu)]^2\\) 가 곱해져 있는 것입니다. \\(g(x) = 1/x\\) 이니까, \\(g'(x) = -x^{-2}, [g'(\mu)]^2 = \mu^{-4}\\) 가 됩니다. 그래서 (2) 를 다시 쓰면 다음과 같습니다 (물론 큰 표본임을 전제합니다):

$$1/(\bar{X}_n) \sim N(1/\mu, \sigma^2/(n\mu^4)) ... (3)$$

이제 이것을 시뮬레이션으로 검증해 보겠습니다. R을 이용하여 \\(N(2, 1^2)\\) 에서 100개의 샘플을 뽑아 그 표본평균의 역수를 추출하는 것을 100,000회 반복하여, 그 분포를 보겠습니다. 코드는 다음과 같습니다:

```r
n_sim <- 100000 # number of sample means
n <- 100 # sample size for each simulation

est <- vector(length=n_sim)
mu <- 2
sd <- 1

for(i in 1:n_sim){
  
  est[i] <- 1/mean(rnorm(n, mu, sd))

}
```

est라는 변수에 100,000개의 표본평균의 역수들을 저장했습니다. 그 평균과 분산은 다음과 같습니다:

```r
> mean(est)
[1] 0.501209

> var(est)
[1] 0.0006357227
```

mean(est)는 \\(1/\mu=1/2\\)와 거의 일치하는 것을 알 수 있습니다. 그러면 이제 var(est)가 이론적 값과 일치하는지 볼까요? 표본평균의 역수의 이론적 분산은 다음과 같습니다:

$$\sigma^2/(n\mu^4) = 1^2/(100(2^4)) = 0.000625$$

이 값은 실제로 관측된 값인 0.000635와 크게 다르지 않습니다. 시뮬레이션 횟수를 더 늘리면 var(est)는 결국 0.000625에 아주 가까워질 것입니다 (사실 꽤 많이 늘려야 하긴 합니다). 분포도 hist() 함수로 확인해보면 정규분포에 아주 가깝습니다.

내친김에 로그변환에도 델타 메쏘드를 한 번 적용해 봅시다. \\(\log(\mu)\\) 를 \\(\log(\bar{X}_n)\\)으로 추정한다고 해 봅시다. 그러면 \\(g(x)=\log(x)\\)는 미분가능한 함수이기 때문에 큰 표본에서는 \\(\mathbb{E}\big(\log(\bar{X}_n)\big) = \mathbb{E}\big(\log(\mu)\big)\\) 입니다. 그리고 이 추정치의 (큰 표본에서의) 분산을 계산하면, \\(\sigma^2[g'(\mu)]^2/n = 1/400 = 0.0025\\) 입니다. 이제 이 값이 시뮬레이션을 한 값과 일치하는지 봅니다:

```r
n_sim <- 100000 # number of sample means
n <- 100 # sample size for each simulation

est <- vector(length=n_sim)
mu <- 2
sd <- 1

for(i in 1:n_sim){
  
  est[i] <- log(mean(rnorm(n, mu, sd)))
  
}

mean(est)
[1] 0.6917954

var(est)
[1] 0.002509503
```

mean(est)는 \\(\log(\mu)\\) = \\(\log(2)\\) = 0.6931472와 거의 일치합니다. 분산 또한 우리가 이론적으로 계산한 값과 거의 같음을 확인할 수 있습니다. 분포도 확인해보면 정규분포에 아주 가깝습니다.

지금까지 변수가 하나일 때의 델타 메쏘드에 대해 알아보았습니다. 지금까지 내용을 다시 한 번 3줄로 요약합니다:

- 델타 메쏘드는 모수치의 변환에 대해 (근사적) 분포를 구하는 방법이다.

- 모수치의 함수를 추정할 때, 원래 사용하던 추정치를 함수에 바로 대입하는 방식으로 추정할 수 있다. (다만 그 추정치에 대해 중심극한정리가 성립해야 한다.)

- "원래 사용하던 추정치를 함수에 바로 대입한 것"의 기댓값은 참값과 일치한다. 단, 분산은 변화한다. 그리고 그 변화의 비율은 변환에 사용된 함수를 한 번 미분한 것의 제곱에 비례한다.

델타 메쏘드를 사용하면 \\(\text{logit}(p)=\log\big(\frac{p}{1-p}\big)\\) 과 같은 값에 대해서도 마찬가지로 추정할 수 있습니다. 로짓 함수는 미분가능하고, 표본비율 \\(X/n\\)이 중심극한정리를 따르기 때문입니다. 

그런데 만약 우리가 추정하고자 하는 변환의 입력값 (모수치) 이 1차원이 아니라 2차원, 아니 그 이상이면 어떻게 하나요? 방법은 똑같습니다. 중심극한정리가 성립하는 추정치를 변환에 넣어주고, 그 분산을 구할 때는 변환에 사용된 함수를 "한 번 미분"한 값의 "제곱"을 원래 추정치의 "분산"에 곱해주면 됩니다. 그런데 이제 변수가 하나가 아니라 둘 이상이기 때문에, 사용하는 개념이 달라질 뿐입니다. 즉 "한 번 미분한 것" 은 이제 그래디언트 gradient 라는 것이 되고, "제곱"은 이차형식 quadratic form 이 되며, "분산"은 공분산행렬 covariance matrix 이 됩니다. 하지만 이것들은 개념적으로는 변수가 하나인 경우와 하나도 다를 게 없습니다. 그러니까 전혀 어렵게 생각하실 필요가 없습니다. [3] Mediation analysis의 경우에 적용하자면, 이제 "모수치"는 \\((a,b)^T\\) 라는 벡터가 되고, "변환"은 \\(f\big((a,b)^T\big) = ab\\)가 됩니다.

다음 글에서는 (드디어!) 다변량 델타 메쏘드를 어떻게 소벨 테스트에 적용하는지 설명하겠습니다. 지금까지의 논의를 잘 따라오신 독자라면 어렵지 않게 이해하실 수 있을 것입니다.

참고문헌

Casella, G., & Berger, R. L. (2002). Statistical inference (Vol. 2). Pacific Grove, CA: Duxbury.

[1] 단, 표본이 상당히 커야 한다는 단서가 붙습니다. 표본이 크지 않으면 여기서 유도하는 분포는 꽤 크게 틀릴 수 있습니다.

[2] http://www.math.umt.edu/patterson/Delta.pdf

[3] 이것을 "다변량 델타 메쏘드" multivariate delta method 라 부릅니다. 다변량 델타 메쏘드가 바로 소벨 테스트의 핵심입니다.
